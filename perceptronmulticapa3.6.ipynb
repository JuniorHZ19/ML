{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuniorHZ19/ML/blob/main/perceptronmulticapa3.6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nEH5XojTlDKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec238a7d-ac27-4b0d-c1f2-1dd873d992a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "class MiDataSet(Dataset):\n",
        "\n",
        "  def __init__(self,csv_file):\n",
        "\n",
        "     data=pd.read_csv(csv_file)\n",
        "\n",
        "     self.x,self.y= self.limpiezaDatos(data)\n",
        "\n",
        "     self.samples=self.y.shape[0]\n",
        "\n",
        "\n",
        "  def __getitem__(self,id):\n",
        "\n",
        "   return self.x[id],self.y[id]\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "   return self.samples\n",
        "\n",
        "\n",
        "  def limpiezaDatos(self,data):\n",
        "\n",
        "    data=data.dropna(how=\"all\")\n",
        "\n",
        "    data=data.drop_duplicates()\n",
        "\n",
        "    data=data.drop(columns=[\"name\",\"ticket\",\"cabin\",\"boat\",\"body\",\"home.dest\"])\n",
        "\n",
        "    data[[\"age\",\"fare\"]]=data[[\"age\",\"fare\"]].fillna(data[[\"age\",\"fare\"]].mean())\n",
        "\n",
        "    data[\"embarked\"]=data[\"embarked\"].fillna(\"S\")\n",
        "\n",
        "    data[\"age\"]=data[\"age\"].astype(int)\n",
        "\n",
        "    data=pd.get_dummies (data,columns=[\"sex\",\"embarked\"],prefix=[\"sex\",\"embarked\"])\n",
        "\n",
        "    variables_x=data.drop(columns=[\"survived\"])\n",
        "\n",
        "    print(variables_x.head())\n",
        "\n",
        "    print(data[\"survived\"].head())\n",
        "    self.scaler=StandardScaler()\n",
        "\n",
        "    variables_x_esclados=self.scaler.fit_transform(variables_x)\n",
        "\n",
        "    variable_y=data[\"survived\"].values\n",
        "\n",
        "\n",
        "    datos_x=torch.from_numpy(variables_x_esclados).float()\n",
        "\n",
        "    datos_y=torch.from_numpy(variable_y).float()\n",
        "\n",
        "\n",
        "\n",
        "    return datos_x,  datos_y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S7i_BABFA3pQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "mis_datos=MiDataSet(\"/content/titanic.csv\")\n",
        "\n",
        "\n",
        "\n",
        "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(mis_datos.x, mis_datos.y, test_size=0.2, random_state=0)\n",
        "\n",
        "print(X_entrenamiento.shape)\n",
        "\n",
        "print(X_prueba.shape)\n",
        "\n",
        "print(y_entrenamiento.shape)\n",
        "\n",
        "print(y_prueba.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zOqxrfSRJivq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91aa83de-bfab-40bc-e739-aa43b6a1a7d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   pclass  age  sibsp  parch      fare  sex_female  sex_male  embarked_C  \\\n",
            "0       1   29      0      0  211.3375           1         0           0   \n",
            "1       1    0      1      2  151.5500           0         1           0   \n",
            "2       1    2      1      2  151.5500           1         0           0   \n",
            "3       1   30      1      2  151.5500           0         1           0   \n",
            "4       1   25      1      2  151.5500           1         0           0   \n",
            "\n",
            "   embarked_Q  embarked_S  \n",
            "0           0           1  \n",
            "1           0           1  \n",
            "2           0           1  \n",
            "3           0           1  \n",
            "4           0           1  \n",
            "0    1\n",
            "1    1\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: survived, dtype: int64\n",
            "torch.Size([1047, 10])\n",
            "torch.Size([262, 10])\n",
            "torch.Size([1047])\n",
            "torch.Size([262])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "conjunto_entrenamiento = TensorDataset(X_entrenamiento, y_entrenamiento)\n",
        "\n",
        "conjunto_prueba = TensorDataset(X_prueba, y_prueba)\n",
        "\n",
        "\n",
        "\n",
        "data_por_lote_entrenamiento=DataLoader(conjunto_entrenamiento,batch_size=100,shuffle=True)\n",
        "\n",
        "data_por_por_lote_test=DataLoader(conjunto_prueba,batch_size=100,shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "#datos_features_train,datos_label_train=next(iter(data_por_lote_entrenamiento))\n",
        "\n",
        "#datos_features_test,datos_label_test=next(iter(data_por_por_lote_test))\n",
        "\n",
        "\n",
        "print(data_por_lote_entrenamiento.batch_size)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2jQ67LCbKprh",
        "outputId": "30fe48f6-6fb3-4170-f478-2fdf2bf1da5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "modelo=torch.Sequential(\n",
        "\n",
        "                        torch.nn.Linear(input_size,3),\n",
        "                        torch.nn.ReLU(),\n",
        "\n",
        "                        torch.nn.Linear(3,4),\n",
        "                        torch.nn.ReLU(),\n",
        "\n",
        "                        torch.nn.Linear(4,1),\n",
        "                        torch.nn.Sigmoid()\n",
        ")"
      ],
      "metadata": {
        "id": "7WMFZMRih-Tv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "ce3ef148-3853-453d-bcd4-2c2ab5c7172e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-aa34abe5cb9d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m modelo=torch.Sequential(\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1833\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module '{__name__}' has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'Sequential'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "class PerceptronMulticapa(nn.Module):\n",
        "\n",
        "   def __init__(self,input_size):\n",
        "    super(PerceptronMulticapa,self).__init__()\n",
        "\n",
        "    self.capa_oculta1=nn.Linear(input_size,1000)\n",
        "\n",
        "    self.capa_oculta2=nn.Linear(1000,1000)\n",
        "\n",
        "    self.capa_oculta3=nn.Linear(1000,500)\n",
        "\n",
        "    self.capa_salida =nn.Linear(500,1)\n",
        "\n",
        "   def forward(self,x):\n",
        "\n",
        "     x=self.capa_oculta1(x)\n",
        "     x=F.relu(x)\n",
        "\n",
        "     x=self.capa_oculta2(x)\n",
        "     x=F.relu(x)\n",
        "\n",
        "     x=self.capa_oculta3(x)\n",
        "     x=F.relu(x)\n",
        "\n",
        "     x=self.capa_salida(x)\n",
        "     output=torch.sigmoid(x)\n",
        "\n",
        "\n",
        "     return output\n"
      ],
      "metadata": {
        "id": "pPePfzy31mvx"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA está disponible.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"CUDA no está disponible. Se utilizará la CPU.\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "xwtxORPcuDNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45909f91-96fe-4f5d-dd56-b7456b0cadbb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA está disponible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#funcion clasificador:\n",
        "def clasificador(y_pred_test):\n",
        "\n",
        "  umbral = 0.6\n",
        "  y_pred_test_binario = (y_pred_test >= umbral).to(torch.float32)\n",
        "\n",
        "  return y_pred_test_binario\n",
        "\n",
        "#funcion acutity:\n",
        "def accurity(y_test,y_real):\n",
        "   correctos=0\n",
        "   for predicho, real in zip(y_test, y_real):\n",
        "    if predicho==real:\n",
        "     correctos+=1\n",
        "   return correctos/len(y_test)\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "\n",
        "def TrainMLP(modelo,epochs,optimisador,criterio,input_size,data_por_lote_entrenamiento,data_por_por_lote_test):\n",
        "\n",
        " for epoch in range(epochs):\n",
        "\n",
        "  total_train_loss = 0.0\n",
        "  num_train_batches = len(data_por_lote_entrenamiento)\n",
        "  modelo.train()\n",
        "\n",
        "  for x_entrenamiento,y_entrenamiento in (data_por_lote_entrenamiento):\n",
        "   x_entrenamiento,y_entrenamiento=x_entrenamiento.to(device),y_entrenamiento.to(device)\n",
        "\n",
        "   y_predict=modelo(x_entrenamiento)\n",
        "   loss=criterio(y_predict,y_entrenamiento.view(-1,1))\n",
        "   optimisador.zero_grad()\n",
        "   loss.backward()\n",
        "   optimisador.step()\n",
        "   optimisador.zero_grad()\n",
        "   total_train_loss+=loss.item()\n",
        "\n",
        "  modelo.eval()\n",
        "  with torch.no_grad():\n",
        "    total_test_accuracy = 0.0\n",
        "    num_test_batches = len(data_por_por_lote_test)\n",
        "\n",
        "    for X_prueba,y_prueba in (data_por_por_lote_test):\n",
        "\n",
        "     X_prueba,y_prueba=X_prueba.to(device),y_prueba.to(device)\n",
        "     y_predict_test=modelo(X_prueba)\n",
        "     y_predic_test_clasificado=clasificador(y_predict_test)\n",
        "     Precision=accurity(y_prueba,y_predic_test_clasificado)\n",
        "     total_test_accuracy += Precision\n",
        "  avg_test_accuracy = total_test_accuracy / num_test_batches\n",
        "  avg_train_loss=total_train_loss/num_train_batches\n",
        "  print(f'Epoca[{epoch+1}], Perdida: {avg_train_loss:.4f},Accuryty:{avg_test_accuracy:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "\n",
        "input_sizes=10\n",
        "\n",
        "PerceptronMulti=PerceptronMulticapa(input_sizes)\n",
        "\n",
        "criterios=nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer=optim.Adam(PerceptronMulti.parameters(),lr=0.00001)\n",
        "\n",
        "epocas=2500\n",
        "\n",
        "PerceptronMulti=PerceptronMulti.to(device)\n",
        "\n",
        "TrainMLP(PerceptronMulti,epocas,optimizer,criterios,input_sizes,data_por_lote_entrenamiento,data_por_por_lote_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#nuevo datos:\n",
        "\n",
        "def escalarNuevaData(data):\n",
        "\n",
        "    scaler=StandardScaler()\n",
        "\n",
        "    datos_escalados=scaler.fit_transform(data)\n",
        "\n",
        "    datos_x_tensor=torch.from_numpy(datos_escalados).float()\n",
        "\n",
        "    return datos_x_tensor\n",
        "\n",
        "nuevo_x=escalarNuevaData([[1,29,0,0,211,1,0,0,0,1]])\n",
        "\n",
        "y_predict=PerceptronMulti(nuevo_x)\n",
        "\n",
        "print(clasificador(y_predict))\n",
        "\n"
      ],
      "metadata": {
        "id": "eb2AfYxQchgT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "802397e1-e218-49b3-bda6-7e7757726944"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca[1], Perdida: 0.7848,Accuryty:0.6238\n",
            "Epoca[2], Perdida: 0.7750,Accuryty:0.6135\n",
            "Epoca[3], Perdida: 0.7690,Accuryty:0.6135\n",
            "Epoca[4], Perdida: 0.7613,Accuryty:0.6156\n",
            "Epoca[5], Perdida: 0.7546,Accuryty:0.6156\n",
            "Epoca[6], Perdida: 0.7468,Accuryty:0.6278\n",
            "Epoca[7], Perdida: 0.7409,Accuryty:0.6115\n",
            "Epoca[8], Perdida: 0.7347,Accuryty:0.6176\n",
            "Epoca[9], Perdida: 0.7240,Accuryty:0.6197\n",
            "Epoca[10], Perdida: 0.7170,Accuryty:0.6386\n",
            "Epoca[11], Perdida: 0.7055,Accuryty:0.6575\n",
            "Epoca[12], Perdida: 0.6958,Accuryty:0.6556\n",
            "Epoca[13], Perdida: 0.6882,Accuryty:0.6748\n",
            "Epoca[14], Perdida: 0.6813,Accuryty:0.6917\n",
            "Epoca[15], Perdida: 0.6752,Accuryty:0.7268\n",
            "Epoca[16], Perdida: 0.6691,Accuryty:0.7232\n",
            "Epoca[17], Perdida: 0.6645,Accuryty:0.7514\n",
            "Epoca[18], Perdida: 0.6605,Accuryty:0.7453\n",
            "Epoca[19], Perdida: 0.6579,Accuryty:0.7601\n",
            "Epoca[20], Perdida: 0.6553,Accuryty:0.7675\n",
            "Epoca[21], Perdida: 0.6508,Accuryty:0.7675\n",
            "Epoca[22], Perdida: 0.6498,Accuryty:0.7566\n",
            "Epoca[23], Perdida: 0.6479,Accuryty:0.7709\n",
            "Epoca[24], Perdida: 0.6445,Accuryty:0.7747\n",
            "Epoca[25], Perdida: 0.6439,Accuryty:0.7814\n",
            "Epoca[26], Perdida: 0.6442,Accuryty:0.7699\n",
            "Epoca[27], Perdida: 0.6436,Accuryty:0.7712\n",
            "Epoca[28], Perdida: 0.6439,Accuryty:0.7862\n",
            "Epoca[29], Perdida: 0.6396,Accuryty:0.7781\n",
            "Epoca[30], Perdida: 0.6428,Accuryty:0.7834\n",
            "Epoca[31], Perdida: 0.6388,Accuryty:0.7760\n",
            "Epoca[32], Perdida: 0.6389,Accuryty:0.7794\n",
            "Epoca[33], Perdida: 0.6381,Accuryty:0.7814\n",
            "Epoca[34], Perdida: 0.6380,Accuryty:0.7842\n",
            "Epoca[35], Perdida: 0.6371,Accuryty:0.7855\n",
            "Epoca[36], Perdida: 0.6372,Accuryty:0.7773\n",
            "Epoca[37], Perdida: 0.6365,Accuryty:0.7875\n",
            "Epoca[38], Perdida: 0.6370,Accuryty:0.7814\n",
            "Epoca[39], Perdida: 0.6355,Accuryty:0.7834\n",
            "Epoca[40], Perdida: 0.6362,Accuryty:0.7875\n",
            "Epoca[41], Perdida: 0.6346,Accuryty:0.7732\n",
            "Epoca[42], Perdida: 0.6355,Accuryty:0.7896\n",
            "Epoca[43], Perdida: 0.6347,Accuryty:0.7814\n",
            "Epoca[44], Perdida: 0.6357,Accuryty:0.7875\n",
            "Epoca[45], Perdida: 0.6355,Accuryty:0.7847\n",
            "Epoca[46], Perdida: 0.6341,Accuryty:0.7929\n",
            "Epoca[47], Perdida: 0.6346,Accuryty:0.7773\n",
            "Epoca[48], Perdida: 0.6312,Accuryty:0.7745\n",
            "Epoca[49], Perdida: 0.6341,Accuryty:0.7773\n",
            "Epoca[50], Perdida: 0.6325,Accuryty:0.7773\n",
            "Epoca[51], Perdida: 0.6328,Accuryty:0.7834\n",
            "Epoca[52], Perdida: 0.6329,Accuryty:0.7847\n",
            "Epoca[53], Perdida: 0.6322,Accuryty:0.7753\n",
            "Epoca[54], Perdida: 0.6301,Accuryty:0.7773\n",
            "Epoca[55], Perdida: 0.6311,Accuryty:0.7834\n",
            "Epoca[56], Perdida: 0.6345,Accuryty:0.7916\n",
            "Epoca[57], Perdida: 0.6318,Accuryty:0.7794\n",
            "Epoca[58], Perdida: 0.6312,Accuryty:0.7753\n",
            "Epoca[59], Perdida: 0.6310,Accuryty:0.7814\n",
            "Epoca[60], Perdida: 0.6320,Accuryty:0.7868\n",
            "Epoca[61], Perdida: 0.6332,Accuryty:0.7888\n",
            "Epoca[62], Perdida: 0.6290,Accuryty:0.7875\n",
            "Epoca[63], Perdida: 0.6301,Accuryty:0.7794\n",
            "Epoca[64], Perdida: 0.6326,Accuryty:0.7909\n",
            "Epoca[65], Perdida: 0.6332,Accuryty:0.7909\n",
            "Epoca[66], Perdida: 0.6309,Accuryty:0.7909\n",
            "Epoca[67], Perdida: 0.6305,Accuryty:0.7881\n",
            "Epoca[68], Perdida: 0.6321,Accuryty:0.7806\n",
            "Epoca[69], Perdida: 0.6324,Accuryty:0.7868\n",
            "Epoca[70], Perdida: 0.6297,Accuryty:0.7840\n",
            "Epoca[71], Perdida: 0.6323,Accuryty:0.7799\n",
            "Epoca[72], Perdida: 0.6317,Accuryty:0.7901\n",
            "Epoca[73], Perdida: 0.6318,Accuryty:0.7983\n",
            "Epoca[74], Perdida: 0.6300,Accuryty:0.7922\n",
            "Epoca[75], Perdida: 0.6299,Accuryty:0.7881\n",
            "Epoca[76], Perdida: 0.6306,Accuryty:0.7888\n",
            "Epoca[77], Perdida: 0.6306,Accuryty:0.7860\n",
            "Epoca[78], Perdida: 0.6315,Accuryty:0.7819\n",
            "Epoca[79], Perdida: 0.6308,Accuryty:0.7962\n",
            "Epoca[80], Perdida: 0.6304,Accuryty:0.7962\n",
            "Epoca[81], Perdida: 0.6299,Accuryty:0.7819\n",
            "Epoca[82], Perdida: 0.6303,Accuryty:0.7901\n",
            "Epoca[83], Perdida: 0.6311,Accuryty:0.7819\n",
            "Epoca[84], Perdida: 0.6312,Accuryty:0.7942\n",
            "Epoca[85], Perdida: 0.6309,Accuryty:0.7860\n",
            "Epoca[86], Perdida: 0.6301,Accuryty:0.7942\n",
            "Epoca[87], Perdida: 0.6304,Accuryty:0.7922\n",
            "Epoca[88], Perdida: 0.6297,Accuryty:0.7766\n",
            "Epoca[89], Perdida: 0.6301,Accuryty:0.7888\n",
            "Epoca[90], Perdida: 0.6309,Accuryty:0.7827\n",
            "Epoca[91], Perdida: 0.6276,Accuryty:0.7888\n",
            "Epoca[92], Perdida: 0.6316,Accuryty:0.7847\n",
            "Epoca[93], Perdida: 0.6296,Accuryty:0.7745\n",
            "Epoca[94], Perdida: 0.6300,Accuryty:0.7834\n",
            "Epoca[95], Perdida: 0.6300,Accuryty:0.7773\n",
            "Epoca[96], Perdida: 0.6321,Accuryty:0.7875\n",
            "Epoca[97], Perdida: 0.6291,Accuryty:0.7712\n",
            "Epoca[98], Perdida: 0.6303,Accuryty:0.7847\n",
            "Epoca[99], Perdida: 0.6286,Accuryty:0.7868\n",
            "Epoca[100], Perdida: 0.6308,Accuryty:0.7901\n",
            "Epoca[101], Perdida: 0.6305,Accuryty:0.7819\n",
            "Epoca[102], Perdida: 0.6285,Accuryty:0.7942\n",
            "Epoca[103], Perdida: 0.6298,Accuryty:0.7847\n",
            "Epoca[104], Perdida: 0.6314,Accuryty:0.7894\n",
            "Epoca[105], Perdida: 0.6258,Accuryty:0.7786\n",
            "Epoca[106], Perdida: 0.6287,Accuryty:0.7881\n",
            "Epoca[107], Perdida: 0.6282,Accuryty:0.7827\n",
            "Epoca[108], Perdida: 0.6302,Accuryty:0.7929\n",
            "Epoca[109], Perdida: 0.6292,Accuryty:0.7909\n",
            "Epoca[110], Perdida: 0.6291,Accuryty:0.7847\n",
            "Epoca[111], Perdida: 0.6284,Accuryty:0.7942\n",
            "Epoca[112], Perdida: 0.6295,Accuryty:0.7766\n",
            "Epoca[113], Perdida: 0.6301,Accuryty:0.7806\n",
            "Epoca[114], Perdida: 0.6288,Accuryty:0.7888\n",
            "Epoca[115], Perdida: 0.6288,Accuryty:0.7860\n",
            "Epoca[116], Perdida: 0.6293,Accuryty:0.7847\n",
            "Epoca[117], Perdida: 0.6276,Accuryty:0.7806\n",
            "Epoca[118], Perdida: 0.6298,Accuryty:0.7766\n",
            "Epoca[119], Perdida: 0.6285,Accuryty:0.7827\n",
            "Epoca[120], Perdida: 0.6267,Accuryty:0.7847\n",
            "Epoca[121], Perdida: 0.6282,Accuryty:0.7766\n",
            "Epoca[122], Perdida: 0.6280,Accuryty:0.7909\n",
            "Epoca[123], Perdida: 0.6304,Accuryty:0.7745\n",
            "Epoca[124], Perdida: 0.6299,Accuryty:0.7942\n",
            "Epoca[125], Perdida: 0.6277,Accuryty:0.7847\n",
            "Epoca[126], Perdida: 0.6284,Accuryty:0.7901\n",
            "Epoca[127], Perdida: 0.6273,Accuryty:0.7806\n",
            "Epoca[128], Perdida: 0.6286,Accuryty:0.7786\n",
            "Epoca[129], Perdida: 0.6288,Accuryty:0.7888\n",
            "Epoca[130], Perdida: 0.6264,Accuryty:0.7745\n",
            "Epoca[131], Perdida: 0.6313,Accuryty:0.7901\n",
            "Epoca[132], Perdida: 0.6299,Accuryty:0.8011\n",
            "Epoca[133], Perdida: 0.6275,Accuryty:0.7909\n",
            "Epoca[134], Perdida: 0.6286,Accuryty:0.7868\n",
            "Epoca[135], Perdida: 0.6267,Accuryty:0.7786\n",
            "Epoca[136], Perdida: 0.6274,Accuryty:0.7988\n",
            "Epoca[137], Perdida: 0.6289,Accuryty:0.7947\n",
            "Epoca[138], Perdida: 0.6286,Accuryty:0.7894\n",
            "Epoca[139], Perdida: 0.6263,Accuryty:0.7868\n",
            "Epoca[140], Perdida: 0.6277,Accuryty:0.7853\n",
            "Epoca[141], Perdida: 0.6250,Accuryty:0.7975\n",
            "Epoca[142], Perdida: 0.6302,Accuryty:0.7975\n",
            "Epoca[143], Perdida: 0.6274,Accuryty:0.7922\n",
            "Epoca[144], Perdida: 0.6259,Accuryty:0.7962\n",
            "Epoca[145], Perdida: 0.6275,Accuryty:0.7975\n",
            "Epoca[146], Perdida: 0.6273,Accuryty:0.7955\n",
            "Epoca[147], Perdida: 0.6286,Accuryty:0.7894\n",
            "Epoca[148], Perdida: 0.6284,Accuryty:0.8016\n",
            "Epoca[149], Perdida: 0.6265,Accuryty:0.7942\n",
            "Epoca[150], Perdida: 0.6251,Accuryty:0.7962\n",
            "Epoca[151], Perdida: 0.6278,Accuryty:0.7934\n",
            "Epoca[152], Perdida: 0.6279,Accuryty:0.8016\n",
            "Epoca[153], Perdida: 0.6298,Accuryty:0.8062\n",
            "Epoca[154], Perdida: 0.6276,Accuryty:0.7922\n",
            "Epoca[155], Perdida: 0.6267,Accuryty:0.7881\n",
            "Epoca[156], Perdida: 0.6267,Accuryty:0.7996\n",
            "Epoca[157], Perdida: 0.6288,Accuryty:0.7947\n",
            "Epoca[158], Perdida: 0.6278,Accuryty:0.7873\n",
            "Epoca[159], Perdida: 0.6303,Accuryty:0.7860\n",
            "Epoca[160], Perdida: 0.6272,Accuryty:0.7868\n",
            "Epoca[161], Perdida: 0.6257,Accuryty:0.7766\n",
            "Epoca[162], Perdida: 0.6269,Accuryty:0.7922\n",
            "Epoca[163], Perdida: 0.6258,Accuryty:0.7914\n",
            "Epoca[164], Perdida: 0.6261,Accuryty:0.7914\n",
            "Epoca[165], Perdida: 0.6272,Accuryty:0.7860\n",
            "Epoca[166], Perdida: 0.6278,Accuryty:0.7934\n",
            "Epoca[167], Perdida: 0.6273,Accuryty:0.7840\n",
            "Epoca[168], Perdida: 0.6285,Accuryty:0.7860\n",
            "Epoca[169], Perdida: 0.6266,Accuryty:0.7840\n",
            "Epoca[170], Perdida: 0.6273,Accuryty:0.7922\n",
            "Epoca[171], Perdida: 0.6250,Accuryty:0.7947\n",
            "Epoca[172], Perdida: 0.6294,Accuryty:0.7968\n",
            "Epoca[173], Perdida: 0.6255,Accuryty:0.7873\n",
            "Epoca[174], Perdida: 0.6265,Accuryty:0.7934\n",
            "Epoca[175], Perdida: 0.6295,Accuryty:0.7975\n",
            "Epoca[176], Perdida: 0.6282,Accuryty:0.7996\n",
            "Epoca[177], Perdida: 0.6266,Accuryty:0.8016\n",
            "Epoca[178], Perdida: 0.6269,Accuryty:0.7934\n",
            "Epoca[179], Perdida: 0.6258,Accuryty:0.7955\n",
            "Epoca[180], Perdida: 0.6277,Accuryty:0.7934\n",
            "Epoca[181], Perdida: 0.6272,Accuryty:0.7894\n",
            "Epoca[182], Perdida: 0.6277,Accuryty:0.7955\n",
            "Epoca[183], Perdida: 0.6278,Accuryty:0.7983\n",
            "Epoca[184], Perdida: 0.6250,Accuryty:0.7873\n",
            "Epoca[185], Perdida: 0.6292,Accuryty:0.8009\n",
            "Epoca[186], Perdida: 0.6299,Accuryty:0.8070\n",
            "Epoca[187], Perdida: 0.6279,Accuryty:0.7847\n",
            "Epoca[188], Perdida: 0.6266,Accuryty:0.7949\n",
            "Epoca[189], Perdida: 0.6270,Accuryty:0.7827\n",
            "Epoca[190], Perdida: 0.6255,Accuryty:0.7955\n",
            "Epoca[191], Perdida: 0.6248,Accuryty:0.7947\n",
            "Epoca[192], Perdida: 0.6257,Accuryty:0.8009\n",
            "Epoca[193], Perdida: 0.6274,Accuryty:0.8022\n",
            "Epoca[194], Perdida: 0.6252,Accuryty:0.7988\n",
            "Epoca[195], Perdida: 0.6273,Accuryty:0.7940\n",
            "Epoca[196], Perdida: 0.6265,Accuryty:0.7968\n",
            "Epoca[197], Perdida: 0.6261,Accuryty:0.7962\n",
            "Epoca[198], Perdida: 0.6266,Accuryty:0.8042\n",
            "Epoca[199], Perdida: 0.6279,Accuryty:0.7960\n",
            "Epoca[200], Perdida: 0.6265,Accuryty:0.8042\n",
            "Epoca[201], Perdida: 0.6266,Accuryty:0.8083\n",
            "Epoca[202], Perdida: 0.6266,Accuryty:0.7981\n",
            "Epoca[203], Perdida: 0.6285,Accuryty:0.7940\n",
            "Epoca[204], Perdida: 0.6265,Accuryty:0.8062\n",
            "Epoca[205], Perdida: 0.6266,Accuryty:0.8042\n",
            "Epoca[206], Perdida: 0.6266,Accuryty:0.8001\n",
            "Epoca[207], Perdida: 0.6276,Accuryty:0.7940\n",
            "Epoca[208], Perdida: 0.6235,Accuryty:0.7981\n",
            "Epoca[209], Perdida: 0.6268,Accuryty:0.8124\n",
            "Epoca[210], Perdida: 0.6258,Accuryty:0.7960\n",
            "Epoca[211], Perdida: 0.6255,Accuryty:0.7878\n",
            "Epoca[212], Perdida: 0.6249,Accuryty:0.8042\n",
            "Epoca[213], Perdida: 0.6251,Accuryty:0.8062\n",
            "Epoca[214], Perdida: 0.6264,Accuryty:0.8137\n",
            "Epoca[215], Perdida: 0.6256,Accuryty:0.8055\n",
            "Epoca[216], Perdida: 0.6261,Accuryty:0.8055\n",
            "Epoca[217], Perdida: 0.6255,Accuryty:0.8014\n",
            "Epoca[218], Perdida: 0.6266,Accuryty:0.8034\n",
            "Epoca[219], Perdida: 0.6269,Accuryty:0.8055\n",
            "Epoca[220], Perdida: 0.6246,Accuryty:0.8075\n",
            "Epoca[221], Perdida: 0.6280,Accuryty:0.8027\n",
            "Epoca[222], Perdida: 0.6248,Accuryty:0.8203\n",
            "Epoca[223], Perdida: 0.6232,Accuryty:0.8162\n",
            "Epoca[224], Perdida: 0.6247,Accuryty:0.8162\n",
            "Epoca[225], Perdida: 0.6265,Accuryty:0.8060\n",
            "Epoca[226], Perdida: 0.6233,Accuryty:0.8060\n",
            "Epoca[227], Perdida: 0.6252,Accuryty:0.8122\n",
            "Epoca[228], Perdida: 0.6246,Accuryty:0.8224\n",
            "Epoca[229], Perdida: 0.6238,Accuryty:0.8224\n",
            "Epoca[230], Perdida: 0.6238,Accuryty:0.8122\n",
            "Epoca[231], Perdida: 0.6243,Accuryty:0.8183\n",
            "Epoca[232], Perdida: 0.6239,Accuryty:0.8122\n",
            "Epoca[233], Perdida: 0.6240,Accuryty:0.8142\n",
            "Epoca[234], Perdida: 0.6244,Accuryty:0.8081\n",
            "Epoca[235], Perdida: 0.6253,Accuryty:0.8060\n",
            "Epoca[236], Perdida: 0.6233,Accuryty:0.8162\n",
            "Epoca[237], Perdida: 0.6232,Accuryty:0.8081\n",
            "Epoca[238], Perdida: 0.6228,Accuryty:0.8081\n",
            "Epoca[239], Perdida: 0.6243,Accuryty:0.8122\n",
            "Epoca[240], Perdida: 0.6249,Accuryty:0.8183\n",
            "Epoca[241], Perdida: 0.6255,Accuryty:0.8122\n",
            "Epoca[242], Perdida: 0.6227,Accuryty:0.8081\n",
            "Epoca[243], Perdida: 0.6244,Accuryty:0.8142\n",
            "Epoca[244], Perdida: 0.6228,Accuryty:0.8081\n",
            "Epoca[245], Perdida: 0.6246,Accuryty:0.8122\n",
            "Epoca[246], Perdida: 0.6242,Accuryty:0.8101\n",
            "Epoca[247], Perdida: 0.6220,Accuryty:0.8081\n",
            "Epoca[248], Perdida: 0.6248,Accuryty:0.8060\n",
            "Epoca[249], Perdida: 0.6240,Accuryty:0.8265\n",
            "Epoca[250], Perdida: 0.6236,Accuryty:0.8142\n",
            "Epoca[251], Perdida: 0.6221,Accuryty:0.8088\n",
            "Epoca[252], Perdida: 0.6209,Accuryty:0.8047\n",
            "Epoca[253], Perdida: 0.6228,Accuryty:0.8047\n",
            "Epoca[254], Perdida: 0.6232,Accuryty:0.8047\n",
            "Epoca[255], Perdida: 0.6212,Accuryty:0.8203\n",
            "Epoca[256], Perdida: 0.6229,Accuryty:0.8183\n",
            "Epoca[257], Perdida: 0.6236,Accuryty:0.8101\n",
            "Epoca[258], Perdida: 0.6239,Accuryty:0.8060\n",
            "Epoca[259], Perdida: 0.6219,Accuryty:0.8162\n",
            "Epoca[260], Perdida: 0.6255,Accuryty:0.8047\n",
            "Epoca[261], Perdida: 0.6237,Accuryty:0.8101\n",
            "Epoca[262], Perdida: 0.6200,Accuryty:0.8190\n",
            "Epoca[263], Perdida: 0.6252,Accuryty:0.8162\n",
            "Epoca[264], Perdida: 0.6221,Accuryty:0.8122\n",
            "Epoca[265], Perdida: 0.6230,Accuryty:0.8101\n",
            "Epoca[266], Perdida: 0.6214,Accuryty:0.8109\n",
            "Epoca[267], Perdida: 0.6216,Accuryty:0.8068\n",
            "Epoca[268], Perdida: 0.6225,Accuryty:0.8177\n",
            "Epoca[269], Perdida: 0.6227,Accuryty:0.8224\n",
            "Epoca[270], Perdida: 0.6235,Accuryty:0.8162\n",
            "Epoca[271], Perdida: 0.6245,Accuryty:0.8081\n",
            "Epoca[272], Perdida: 0.6219,Accuryty:0.8142\n",
            "Epoca[273], Perdida: 0.6217,Accuryty:0.8170\n",
            "Epoca[274], Perdida: 0.6224,Accuryty:0.8129\n",
            "Epoca[275], Perdida: 0.6239,Accuryty:0.8088\n",
            "Epoca[276], Perdida: 0.6220,Accuryty:0.8068\n",
            "Epoca[277], Perdida: 0.6223,Accuryty:0.8014\n",
            "Epoca[278], Perdida: 0.6237,Accuryty:0.8040\n",
            "Epoca[279], Perdida: 0.6252,Accuryty:0.8122\n",
            "Epoca[280], Perdida: 0.6216,Accuryty:0.8075\n",
            "Epoca[281], Perdida: 0.6241,Accuryty:0.8190\n",
            "Epoca[282], Perdida: 0.6226,Accuryty:0.7994\n",
            "Epoca[283], Perdida: 0.6223,Accuryty:0.8162\n",
            "Epoca[284], Perdida: 0.6253,Accuryty:0.8047\n",
            "Epoca[285], Perdida: 0.6203,Accuryty:0.8047\n",
            "Epoca[286], Perdida: 0.6218,Accuryty:0.8068\n",
            "Epoca[287], Perdida: 0.6225,Accuryty:0.8109\n",
            "Epoca[288], Perdida: 0.6237,Accuryty:0.8068\n",
            "Epoca[289], Perdida: 0.6223,Accuryty:0.8162\n",
            "Epoca[290], Perdida: 0.6230,Accuryty:0.8109\n",
            "Epoca[291], Perdida: 0.6217,Accuryty:0.8116\n",
            "Epoca[292], Perdida: 0.6243,Accuryty:0.8088\n",
            "Epoca[293], Perdida: 0.6200,Accuryty:0.8027\n",
            "Epoca[294], Perdida: 0.6224,Accuryty:0.8129\n",
            "Epoca[295], Perdida: 0.6231,Accuryty:0.8027\n",
            "Epoca[296], Perdida: 0.6203,Accuryty:0.8055\n",
            "Epoca[297], Perdida: 0.6217,Accuryty:0.7973\n",
            "Epoca[298], Perdida: 0.6216,Accuryty:0.8081\n",
            "Epoca[299], Perdida: 0.6231,Accuryty:0.8129\n",
            "Epoca[300], Perdida: 0.6231,Accuryty:0.8170\n",
            "Epoca[301], Perdida: 0.6239,Accuryty:0.8014\n",
            "Epoca[302], Perdida: 0.6215,Accuryty:0.8068\n",
            "Epoca[303], Perdida: 0.6214,Accuryty:0.8055\n",
            "Epoca[304], Perdida: 0.6223,Accuryty:0.8170\n",
            "Epoca[305], Perdida: 0.6202,Accuryty:0.8170\n",
            "Epoca[306], Perdida: 0.6205,Accuryty:0.8075\n",
            "Epoca[307], Perdida: 0.6239,Accuryty:0.8211\n",
            "Epoca[308], Perdida: 0.6230,Accuryty:0.8027\n",
            "Epoca[309], Perdida: 0.6209,Accuryty:0.8034\n",
            "Epoca[310], Perdida: 0.6204,Accuryty:0.8129\n",
            "Epoca[311], Perdida: 0.6200,Accuryty:0.8137\n",
            "Epoca[312], Perdida: 0.6220,Accuryty:0.8157\n",
            "Epoca[313], Perdida: 0.6198,Accuryty:0.8190\n",
            "Epoca[314], Perdida: 0.6219,Accuryty:0.8149\n",
            "Epoca[315], Perdida: 0.6229,Accuryty:0.8034\n",
            "Epoca[316], Perdida: 0.6224,Accuryty:0.8006\n",
            "Epoca[317], Perdida: 0.6199,Accuryty:0.8042\n",
            "Epoca[318], Perdida: 0.6216,Accuryty:0.7994\n",
            "Epoca[319], Perdida: 0.6216,Accuryty:0.8129\n",
            "Epoca[320], Perdida: 0.6231,Accuryty:0.8096\n",
            "Epoca[321], Perdida: 0.6205,Accuryty:0.8129\n",
            "Epoca[322], Perdida: 0.6235,Accuryty:0.7953\n",
            "Epoca[323], Perdida: 0.6214,Accuryty:0.8190\n",
            "Epoca[324], Perdida: 0.6221,Accuryty:0.8068\n",
            "Epoca[325], Perdida: 0.6235,Accuryty:0.7994\n",
            "Epoca[326], Perdida: 0.6222,Accuryty:0.8034\n",
            "Epoca[327], Perdida: 0.6216,Accuryty:0.8047\n",
            "Epoca[328], Perdida: 0.6218,Accuryty:0.8055\n",
            "Epoca[329], Perdida: 0.6217,Accuryty:0.8027\n",
            "Epoca[330], Perdida: 0.6231,Accuryty:0.8149\n",
            "Epoca[331], Perdida: 0.6228,Accuryty:0.7953\n",
            "Epoca[332], Perdida: 0.6220,Accuryty:0.8075\n",
            "Epoca[333], Perdida: 0.6212,Accuryty:0.7891\n",
            "Epoca[334], Perdida: 0.6261,Accuryty:0.8014\n",
            "Epoca[335], Perdida: 0.6209,Accuryty:0.7927\n",
            "Epoca[336], Perdida: 0.6214,Accuryty:0.7932\n",
            "Epoca[337], Perdida: 0.6215,Accuryty:0.8075\n",
            "Epoca[338], Perdida: 0.6210,Accuryty:0.7919\n",
            "Epoca[339], Perdida: 0.6237,Accuryty:0.8022\n",
            "Epoca[340], Perdida: 0.6222,Accuryty:0.8075\n",
            "Epoca[341], Perdida: 0.6211,Accuryty:0.7994\n",
            "Epoca[342], Perdida: 0.6204,Accuryty:0.7973\n",
            "Epoca[343], Perdida: 0.6225,Accuryty:0.8055\n",
            "Epoca[344], Perdida: 0.6219,Accuryty:0.8096\n",
            "Epoca[345], Perdida: 0.6210,Accuryty:0.8096\n",
            "Epoca[346], Perdida: 0.6222,Accuryty:0.8096\n",
            "Epoca[347], Perdida: 0.6226,Accuryty:0.8055\n",
            "Epoca[348], Perdida: 0.6210,Accuryty:0.7973\n",
            "Epoca[349], Perdida: 0.6208,Accuryty:0.8075\n",
            "Epoca[350], Perdida: 0.6212,Accuryty:0.7994\n",
            "Epoca[351], Perdida: 0.6207,Accuryty:0.8042\n",
            "Epoca[352], Perdida: 0.6217,Accuryty:0.7973\n",
            "Epoca[353], Perdida: 0.6200,Accuryty:0.8075\n",
            "Epoca[354], Perdida: 0.6214,Accuryty:0.8062\n",
            "Epoca[355], Perdida: 0.6196,Accuryty:0.8088\n",
            "Epoca[356], Perdida: 0.6225,Accuryty:0.8027\n",
            "Epoca[357], Perdida: 0.6216,Accuryty:0.8001\n",
            "Epoca[358], Perdida: 0.6217,Accuryty:0.8001\n",
            "Epoca[359], Perdida: 0.6208,Accuryty:0.7960\n",
            "Epoca[360], Perdida: 0.6215,Accuryty:0.8129\n",
            "Epoca[361], Perdida: 0.6237,Accuryty:0.8068\n",
            "Epoca[362], Perdida: 0.6209,Accuryty:0.8075\n",
            "Epoca[363], Perdida: 0.6205,Accuryty:0.8116\n",
            "Epoca[364], Perdida: 0.6203,Accuryty:0.8014\n",
            "Epoca[365], Perdida: 0.6218,Accuryty:0.7960\n",
            "Epoca[366], Perdida: 0.6216,Accuryty:0.8116\n",
            "Epoca[367], Perdida: 0.6203,Accuryty:0.8170\n",
            "Epoca[368], Perdida: 0.6216,Accuryty:0.8047\n",
            "Epoca[369], Perdida: 0.6212,Accuryty:0.8068\n",
            "Epoca[370], Perdida: 0.6228,Accuryty:0.8062\n",
            "Epoca[371], Perdida: 0.6241,Accuryty:0.8170\n",
            "Epoca[372], Perdida: 0.6206,Accuryty:0.8022\n",
            "Epoca[373], Perdida: 0.6195,Accuryty:0.8006\n",
            "Epoca[374], Perdida: 0.6206,Accuryty:0.8190\n",
            "Epoca[375], Perdida: 0.6216,Accuryty:0.7981\n",
            "Epoca[376], Perdida: 0.6207,Accuryty:0.8075\n",
            "Epoca[377], Perdida: 0.6180,Accuryty:0.8075\n",
            "Epoca[378], Perdida: 0.6206,Accuryty:0.8109\n",
            "Epoca[379], Perdida: 0.6198,Accuryty:0.8170\n",
            "Epoca[380], Perdida: 0.6200,Accuryty:0.8083\n",
            "Epoca[381], Perdida: 0.6218,Accuryty:0.8109\n",
            "Epoca[382], Perdida: 0.6195,Accuryty:0.8062\n",
            "Epoca[383], Perdida: 0.6203,Accuryty:0.8055\n",
            "Epoca[384], Perdida: 0.6207,Accuryty:0.8062\n",
            "Epoca[385], Perdida: 0.6205,Accuryty:0.7940\n",
            "Epoca[386], Perdida: 0.6205,Accuryty:0.8096\n",
            "Epoca[387], Perdida: 0.6204,Accuryty:0.7919\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-e19160f7754a>\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mPerceptronMulti\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPerceptronMulti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mTrainMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPerceptronMulti\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepocas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterios\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_por_lote_entrenamiento\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_por_por_lote_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-e19160f7754a>\u001b[0m in \u001b[0;36mTrainMLP\u001b[0;34m(modelo, epochs, optimisador, criterio, input_size, data_por_lote_entrenamiento, data_por_por_lote_test)\u001b[0m\n\u001b[1;32m     35\u001b[0m    \u001b[0moptimisador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m    \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m    \u001b[0moptimisador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m    \u001b[0moptimisador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m    \u001b[0mtotal_train_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m                             )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 state_steps)\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    312\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stack_if_compiling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0mbias_correction2_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dispatch_sqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbias_correction2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stack_if_compiling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0mbias_correction2_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dispatch_sqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbias_correction2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_dispatch_sqrt\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_dispatch_sqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# float annotation is needed because of torchscript type inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "y_pred_multiclases = torch.tensor([[0.1, 1.8, 0.8, 0.4, 2],\n",
        "                                   [0.5, 2, 3.5, 5, 2.1]])\n",
        "\n",
        "def clasificador(y_pred_test):\n",
        "\n",
        "   max_values_tensor = torch.empty((0,), dtype=torch.float32)\n",
        "\n",
        "   for tensor in y_pred_test:\n",
        "\n",
        "     max_values, max_indices  = torch.max(tensor, dim=0)\n",
        "\n",
        "     max_values_tensor = torch.cat((max_values_tensor, max_indices.unsqueeze(0)))\n",
        "\n",
        "   return max_values_tensor\n",
        "\n",
        "print(clasificador(y_pred_multiclases))\n"
      ],
      "metadata": {
        "id": "7LqpXE2_9vpy",
        "outputId": "c10e4aa3-a539-4e8d-df5a-8dfd2f076f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4., 3.])\n"
          ]
        }
      ]
    }
  ]
}