{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuniorHZ19/ML/blob/main/perceptronmulticapa3.5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nEH5XojTlDKd",
        "outputId": "ec238a7d-ac27-4b0d-c1f2-1dd873d992a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "class MiDataSet(Dataset):\n",
        "\n",
        "  def __init__(self,csv_file):\n",
        "\n",
        "     data=pd.read_csv(csv_file)\n",
        "\n",
        "     self.x,self.y= self.limpiezaDatos(data)\n",
        "\n",
        "     self.samples=self.y.shape[0]\n",
        "\n",
        "\n",
        "  def __getitem__(self,id):\n",
        "\n",
        "   return self.x[id],self.y[id]\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "   return self.samples\n",
        "\n",
        "\n",
        "  def limpiezaDatos(self,data):\n",
        "\n",
        "    data=data.dropna(how=\"all\")\n",
        "\n",
        "    data=data.drop_duplicates()\n",
        "\n",
        "    data=data.drop(columns=[\"name\",\"ticket\",\"cabin\",\"boat\",\"body\",\"home.dest\"])\n",
        "\n",
        "    data[[\"age\",\"fare\"]]=data[[\"age\",\"fare\"]].fillna(data[[\"age\",\"fare\"]].mean())\n",
        "\n",
        "    data[\"embarked\"]=data[\"embarked\"].fillna(\"S\")\n",
        "\n",
        "    data[\"age\"]=data[\"age\"].astype(int)\n",
        "\n",
        "    data=pd.get_dummies (data,columns=[\"sex\",\"embarked\"],prefix=[\"sex\",\"embarked\"])\n",
        "\n",
        "    variables_x=data.drop(columns=[\"survived\"])\n",
        "\n",
        "    print(variables_x.head())\n",
        "\n",
        "    print(data[\"survived\"].head())\n",
        "    self.scaler=StandardScaler()\n",
        "\n",
        "    variables_x_esclados=self.scaler.fit_transform(variables_x)\n",
        "\n",
        "    variable_y=data[\"survived\"].values\n",
        "\n",
        "\n",
        "    datos_x=torch.from_numpy(variables_x_esclados).float()\n",
        "\n",
        "    datos_y=torch.from_numpy(variable_y).float()\n",
        "\n",
        "\n",
        "\n",
        "    return datos_x,  datos_y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S7i_BABFA3pQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "mis_datos=MiDataSet(\"/content/titanic.csv\")\n",
        "\n",
        "\n",
        "\n",
        "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(mis_datos.x, mis_datos.y, test_size=0.2, random_state=0)\n",
        "\n",
        "print(X_entrenamiento.shape)\n",
        "\n",
        "print(X_prueba.shape)\n",
        "\n",
        "print(y_entrenamiento.shape)\n",
        "\n",
        "print(y_prueba.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zOqxrfSRJivq",
        "outputId": "91aa83de-bfab-40bc-e739-aa43b6a1a7d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   pclass  age  sibsp  parch      fare  sex_female  sex_male  embarked_C  \\\n",
            "0       1   29      0      0  211.3375           1         0           0   \n",
            "1       1    0      1      2  151.5500           0         1           0   \n",
            "2       1    2      1      2  151.5500           1         0           0   \n",
            "3       1   30      1      2  151.5500           0         1           0   \n",
            "4       1   25      1      2  151.5500           1         0           0   \n",
            "\n",
            "   embarked_Q  embarked_S  \n",
            "0           0           1  \n",
            "1           0           1  \n",
            "2           0           1  \n",
            "3           0           1  \n",
            "4           0           1  \n",
            "0    1\n",
            "1    1\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: survived, dtype: int64\n",
            "torch.Size([1047, 10])\n",
            "torch.Size([262, 10])\n",
            "torch.Size([1047])\n",
            "torch.Size([262])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "conjunto_entrenamiento = TensorDataset(X_entrenamiento, y_entrenamiento)\n",
        "\n",
        "conjunto_prueba = TensorDataset(X_prueba, y_prueba)\n",
        "\n",
        "\n",
        "\n",
        "data_por_lote_entrenamiento=DataLoader(conjunto_entrenamiento,batch_size=100,shuffle=True)\n",
        "\n",
        "data_por_por_lote_test=DataLoader(conjunto_prueba,batch_size=100,shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "datos_features_train,datos_label_train=next(iter(data_por_lote_entrenamiento))\n",
        "\n",
        "datos_features_test,datos_label_test=next(iter(data_por_por_lote_test))\n",
        "\n",
        "\n",
        "print(datos_features_test.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2jQ67LCbKprh",
        "outputId": "95cd7733-8c93-4929-a934-1faf44454e35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "modelo=torch.Sequential(\n",
        "\n",
        "                        torch.nn.Linear(input_size,3),\n",
        "                        torch.nn.ReLU(),\n",
        "\n",
        "                        torch.nn.Linear(3,4),\n",
        "                        torch.nn.ReLU(),\n",
        "\n",
        "                        torch.nn.Linear(4,1),\n",
        "                        torch.nn.Sigmoid()\n",
        ")"
      ],
      "metadata": {
        "id": "7WMFZMRih-Tv",
        "outputId": "5012e5dc-7eb7-4bd6-a731-ef9d36735098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-aa34abe5cb9d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m modelo=torch.Sequential(\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1833\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module '{__name__}' has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'Sequential'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "class PerceptronMulticapa(nn.Module):\n",
        "\n",
        "   def __init__(self,input_size):\n",
        "    super(PerceptronMulticapa,self).__init__()\n",
        "\n",
        "    self.capa_oculta1=nn.Linear(input_size,1000)\n",
        "\n",
        "    self.capa_oculta2=nn.Linear(1000,500)\n",
        "\n",
        "    self.capa_oculta3=nn.Linear(500,200)\n",
        "\n",
        "    self.capa_salida =nn.Linear(200,1)\n",
        "\n",
        "   def forward(self,x):\n",
        "\n",
        "     x=self.capa_oculta1(x)\n",
        "     x=F.relu(x)\n",
        "\n",
        "     x=self.capa_oculta2(x)\n",
        "     x=F.relu(x)\n",
        "\n",
        "     x=self.capa_oculta3(x)\n",
        "     x=F.relu(x)\n",
        "\n",
        "     x=self.capa_salida(x)\n",
        "     output=torch.sigmoid(x)\n",
        "\n",
        "\n",
        "     return output\n"
      ],
      "metadata": {
        "id": "pPePfzy31mvx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA está disponible.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"CUDA no está disponible. Se utilizará la CPU.\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "xwtxORPcuDNw",
        "outputId": "45909f91-96fe-4f5d-dd56-b7456b0cadbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA está disponible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#funcion clasificador:\n",
        "def clasificador(y_pred_test):\n",
        "\n",
        "  umbral = 0.6\n",
        "  y_pred_test_binario = (y_pred_test >= umbral).to(torch.float32)\n",
        "\n",
        "  return y_pred_test_binario\n",
        "\n",
        "#funcion acutity:\n",
        "def accurity(y_test,y_real):\n",
        "   correctos=0\n",
        "   for predicho, real in zip(y_test, y_real):\n",
        "    if predicho==real:\n",
        "     correctos+=1\n",
        "   return correctos/len(y_test)\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "\n",
        "def TrainMLP(modelo,epochs,optimisador,criterio,input_size,data_por_lote_entrenamiento,data_por_por_lote_test):\n",
        "\n",
        " for epoch in range(epochs):\n",
        "  for x_entrenamiento,y_entrenamiento in (data_por_lote_entrenamiento):\n",
        "   total_train_loss = 0.0\n",
        "   num_train_batches = len(data_por_lote_entrenamiento)\n",
        "   modelo.train()\n",
        "   x_entrenamiento,y_entrenamiento=x_entrenamiento.to(device),y_entrenamiento.to(device)\n",
        "\n",
        "   y_predict=PerceptronMulti(x_entrenamiento)\n",
        "   loss=criterio(y_predict,y_entrenamiento.view(-1,1))\n",
        "   loss.backward()\n",
        "   optimizer.step()\n",
        "   optimizer.zero_grad()\n",
        "   total_train_loss+=loss.item()\n",
        "\n",
        "   modelo.eval()\n",
        "   with torch.no_grad():\n",
        "    for X_prueba,y_prueba in (data_por_por_lote_test):\n",
        "     total_test_accuracy = 0.0\n",
        "     num_test_batches = len(data_por_por_lote_test)\n",
        "     X_prueba,y_prueba=X_prueba.to(device),y_prueba.to(device)\n",
        "     y_predict_test=PerceptronMulti(X_prueba)\n",
        "     y_predic_test_clasificado=clasificador(y_predict_test)\n",
        "     Precision=accurity(y_prueba,y_predic_test_clasificado)\n",
        "     total_test_accuracy += Precision\n",
        "  avg_test_accuracy = total_test_accuracy / num_test_batches\n",
        "  avg_train_loss=total_train_loss/num_train_batches\n",
        "  print(f'Epoca[{epoch+1}], Perdida: {avg_train_loss:.4f},Accuryty:{avg_test_accuracy:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "\n",
        "input_size=X_entrenamiento.shape[1]\n",
        "\n",
        "PerceptronMulti=PerceptronMulticapa(input_size)\n",
        "\n",
        "criterio=nn.BCELoss()\n",
        "\n",
        "optimizer=optim.Adam(PerceptronMulti.parameters(),lr=0.0000001)\n",
        "\n",
        "epochs=500\n",
        "\n",
        "PerceptronMulti=PerceptronMulti.to(device)\n",
        "\n",
        "TrainMLP(PerceptronMulti,epochs,optimizer,criterio,input_size,data_por_lote_entrenamiento,data_por_por_lote_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#nuevo datos:\n",
        "\n",
        "def escalarNuevaData(data):\n",
        "\n",
        "    scaler=StandardScaler()\n",
        "\n",
        "    datos_escalados=scaler.fit_transform(data)\n",
        "\n",
        "    datos_x_tensor=torch.from_numpy(datos_escalados).float()\n",
        "\n",
        "    return datos_x_tensor\n",
        "\n",
        "nuevo_x=escalarNuevaData([[1,29,0,0,211,1,0,0,0,1]])\n",
        "\n",
        "y_predict=PerceptronMulti(nuevo_x)\n",
        "\n",
        "print(clasificador(y_predict))\n",
        "\n"
      ],
      "metadata": {
        "id": "eb2AfYxQchgT",
        "outputId": "469731c9-90d3-469d-e951-514a8a2bbd77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca[1], Perdida: 0.0630,Accuryty:0.2258\n",
            "Epoca[2], Perdida: 0.0631,Accuryty:0.2204\n",
            "Epoca[3], Perdida: 0.0627,Accuryty:0.2043\n",
            "Epoca[4], Perdida: 0.0629,Accuryty:0.2366\n",
            "Epoca[5], Perdida: 0.0630,Accuryty:0.1989\n",
            "Epoca[6], Perdida: 0.0630,Accuryty:0.1828\n",
            "Epoca[7], Perdida: 0.0629,Accuryty:0.1882\n",
            "Epoca[8], Perdida: 0.0626,Accuryty:0.1989\n",
            "Epoca[9], Perdida: 0.0631,Accuryty:0.1828\n",
            "Epoca[10], Perdida: 0.0632,Accuryty:0.2258\n",
            "Epoca[11], Perdida: 0.0628,Accuryty:0.1882\n",
            "Epoca[12], Perdida: 0.0626,Accuryty:0.2151\n",
            "Epoca[13], Perdida: 0.0628,Accuryty:0.2204\n",
            "Epoca[14], Perdida: 0.0627,Accuryty:0.2151\n",
            "Epoca[15], Perdida: 0.0632,Accuryty:0.2097\n",
            "Epoca[16], Perdida: 0.0626,Accuryty:0.2151\n",
            "Epoca[17], Perdida: 0.0626,Accuryty:0.2097\n",
            "Epoca[18], Perdida: 0.0627,Accuryty:0.2258\n",
            "Epoca[19], Perdida: 0.0629,Accuryty:0.1935\n",
            "Epoca[20], Perdida: 0.0627,Accuryty:0.2258\n",
            "Epoca[21], Perdida: 0.0626,Accuryty:0.1828\n",
            "Epoca[22], Perdida: 0.0627,Accuryty:0.2043\n",
            "Epoca[23], Perdida: 0.0626,Accuryty:0.2043\n",
            "Epoca[24], Perdida: 0.0626,Accuryty:0.2473\n",
            "Epoca[25], Perdida: 0.0627,Accuryty:0.1989\n",
            "Epoca[26], Perdida: 0.0630,Accuryty:0.2151\n",
            "Epoca[27], Perdida: 0.0624,Accuryty:0.1935\n",
            "Epoca[28], Perdida: 0.0625,Accuryty:0.2258\n",
            "Epoca[29], Perdida: 0.0625,Accuryty:0.1989\n",
            "Epoca[30], Perdida: 0.0626,Accuryty:0.2097\n",
            "Epoca[31], Perdida: 0.0626,Accuryty:0.2151\n",
            "Epoca[32], Perdida: 0.0627,Accuryty:0.2043\n",
            "Epoca[33], Perdida: 0.0627,Accuryty:0.2204\n",
            "Epoca[34], Perdida: 0.0626,Accuryty:0.2204\n",
            "Epoca[35], Perdida: 0.0627,Accuryty:0.1935\n",
            "Epoca[36], Perdida: 0.0625,Accuryty:0.1882\n",
            "Epoca[37], Perdida: 0.0628,Accuryty:0.1989\n",
            "Epoca[38], Perdida: 0.0625,Accuryty:0.1935\n",
            "Epoca[39], Perdida: 0.0627,Accuryty:0.2312\n",
            "Epoca[40], Perdida: 0.0624,Accuryty:0.2366\n",
            "Epoca[41], Perdida: 0.0626,Accuryty:0.2204\n",
            "Epoca[42], Perdida: 0.0628,Accuryty:0.2043\n",
            "Epoca[43], Perdida: 0.0624,Accuryty:0.1882\n",
            "Epoca[44], Perdida: 0.0625,Accuryty:0.1720\n",
            "Epoca[45], Perdida: 0.0628,Accuryty:0.1667\n",
            "Epoca[46], Perdida: 0.0626,Accuryty:0.2204\n",
            "Epoca[47], Perdida: 0.0628,Accuryty:0.2097\n",
            "Epoca[48], Perdida: 0.0623,Accuryty:0.2258\n",
            "Epoca[49], Perdida: 0.0626,Accuryty:0.1989\n",
            "Epoca[50], Perdida: 0.0622,Accuryty:0.1935\n",
            "Epoca[51], Perdida: 0.0628,Accuryty:0.1935\n",
            "Epoca[52], Perdida: 0.0626,Accuryty:0.1989\n",
            "Epoca[53], Perdida: 0.0622,Accuryty:0.2097\n",
            "Epoca[54], Perdida: 0.0625,Accuryty:0.1882\n",
            "Epoca[55], Perdida: 0.0622,Accuryty:0.2043\n",
            "Epoca[56], Perdida: 0.0627,Accuryty:0.2097\n",
            "Epoca[57], Perdida: 0.0625,Accuryty:0.1774\n",
            "Epoca[58], Perdida: 0.0624,Accuryty:0.2312\n",
            "Epoca[59], Perdida: 0.0620,Accuryty:0.1828\n",
            "Epoca[60], Perdida: 0.0625,Accuryty:0.2366\n",
            "Epoca[61], Perdida: 0.0622,Accuryty:0.2204\n",
            "Epoca[62], Perdida: 0.0625,Accuryty:0.1559\n",
            "Epoca[63], Perdida: 0.0626,Accuryty:0.2527\n",
            "Epoca[64], Perdida: 0.0620,Accuryty:0.1989\n",
            "Epoca[65], Perdida: 0.0629,Accuryty:0.2151\n",
            "Epoca[66], Perdida: 0.0622,Accuryty:0.2097\n",
            "Epoca[67], Perdida: 0.0624,Accuryty:0.2258\n",
            "Epoca[68], Perdida: 0.0623,Accuryty:0.1989\n",
            "Epoca[69], Perdida: 0.0627,Accuryty:0.1828\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-dc1017a6d728>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mPerceptronMulti\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPerceptronMulti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mTrainMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPerceptronMulti\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_por_lote_entrenamiento\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_por_por_lote_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-dc1017a6d728>\u001b[0m in \u001b[0;36mTrainMLP\u001b[0;34m(modelo, epochs, optimisador, criterio, input_size, data_por_lote_entrenamiento, data_por_por_lote_test)\u001b[0m\n\u001b[1;32m     44\u001b[0m      \u001b[0my_predict_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPerceptronMulti\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_prueba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m      \u001b[0my_predic_test_clasificado\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasificador\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predict_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m      \u001b[0mPrecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccurity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_prueba\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_predic_test_clasificado\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m      \u001b[0mtotal_test_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mPrecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0mavg_test_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_test_accuracy\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_test_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-dc1017a6d728>\u001b[0m in \u001b[0;36maccurity\u001b[0;34m(y_test, y_real)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#funcion clasificador:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclasificador\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mumbral\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0my_pred_test_binario\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred_test\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mumbral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "y_pred_multiclases = torch.tensor([[0.1, 1.8, 0.8, 0.4, 2],\n",
        "                                   [0.5, 2, 3.5, 5, 2.1]])\n",
        "\n",
        "def clasificador(y_pred_test):\n",
        "\n",
        "   max_values_tensor = torch.empty((0,), dtype=torch.float32)\n",
        "\n",
        "   for tensor in y_pred_test:\n",
        "\n",
        "     max_values, max_indices  = torch.max(tensor, dim=0)\n",
        "\n",
        "     max_values_tensor = torch.cat((max_values_tensor, max_indices.unsqueeze(0)))\n",
        "\n",
        "   return max_values_tensor\n",
        "\n",
        "print(clasificador(y_pred_multiclases))\n"
      ],
      "metadata": {
        "id": "7LqpXE2_9vpy",
        "outputId": "c10e4aa3-a539-4e8d-df5a-8dfd2f076f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4., 3.])\n"
          ]
        }
      ]
    }
  ]
}