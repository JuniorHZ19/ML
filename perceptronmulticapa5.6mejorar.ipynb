{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuniorHZ19/ML/blob/main/perceptronmulticapa5.6mejorar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nEH5XojTlDKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07536626-9ce1-48f4-8c65-8dafd5620493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class MiDataSet(Dataset):\n",
        "\n",
        "  def __init__(self,csv_file):\n",
        "\n",
        "     data=pd.read_csv(csv_file)\n",
        "\n",
        "     self.x,self.y= self.limpiezaDatos(data)\n",
        "\n",
        "     self.samples=self.y.shape[0]\n",
        "\n",
        "\n",
        "  def __getitem__(self,id):\n",
        "\n",
        "   return self.x[id],self.y[id]\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "   return self.samples\n",
        "\n",
        "\n",
        "  def limpiezaDatos(self,data):\n",
        "\n",
        "    data=data.dropna(how=\"all\")\n",
        "\n",
        "    data=data.drop_duplicates()\n",
        "\n",
        "    data=data.drop(columns=[\"name\",\"ticket\",\"cabin\",\"boat\",\"body\",\"home.dest\"])\n",
        "\n",
        "    data[[\"age\",\"fare\"]]=data[[\"age\",\"fare\"]].fillna(data[[\"age\",\"fare\"]].mean())\n",
        "\n",
        "    data[\"embarked\"]=data[\"embarked\"].fillna(\"S\")\n",
        "\n",
        "    data[\"age\"]=data[\"age\"].astype(int)\n",
        "\n",
        "    data=pd.get_dummies (data,columns=[\"sex\",\"embarked\"],prefix=[\"sex\",\"embarked\"])\n",
        "\n",
        "    variables_x=data.drop(columns=[\"survived\"])\n",
        "    print(variables_x.head())\n",
        "    variable_y=data[\"survived\"]\n",
        "\n",
        "    return variables_x.values,  variable_y.values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S7i_BABFA3pQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gmEfz4kydlJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "mis_datos=MiDataSet(\"/content/titanic.csv\")\n",
        "\n",
        "#Estandarizar los datos solo los datos que son conitunos no los categoricos como dumies que tiene 0-1 etc\n",
        "\n",
        "columnas_continuas = [1,4] #columnas no categoricas 1:age 2:fare\n",
        "\n",
        "\n",
        "\n",
        "def normalizar_datos(data,columnas_no_cat,mean_value_continuos=None,std_value_continuos=None):\n",
        " datos_continuos = data[:, columnas_no_cat] #tomaremos los datos de nuestro dataset de esas columnas\n",
        "\n",
        " if mean_value_continuos is  None:\n",
        "  mean_value_continuos = np.mean(datos_continuos, axis=0) #Calculamos el mean de esas columnas\n",
        "\n",
        " if std_value_continuos is  None:\n",
        "  std_value_continuos = np.std(datos_continuos, axis=0) #Calculamos el desviacion  estadar de esas columnas\n",
        "\n",
        " normalized_data_continuos = (datos_continuos - mean_value_continuos) / std_value_continuos #normalizaoms con la desviacion y desviacion estanr cada dato\n",
        " data[:, columnas_no_cat] = normalized_data_continuos #regresmos los datos de las columnas  no categoricas normalizadas de nuevo a los datos\n",
        "\n",
        " return data,mean_value_continuos,std_value_continuos\n",
        "\n",
        "\n",
        "data_x_normalizada,mean_,std_=normalizar_datos(mis_datos.x,columnas_continuas)\n",
        "\n",
        "print(mean_)\n",
        "\n",
        "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(data_x_normalizada, mis_datos.y, test_size=0.2, random_state=0,stratify=mis_datos.y)\n",
        "\n",
        "print(X_entrenamiento.shape)\n",
        "\n",
        "print(X_prueba)\n",
        "\n",
        "print(y_entrenamiento.shape)\n",
        "\n",
        "print(y_prueba)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zOqxrfSRJivq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e98105de-a6c5-4379-e2f2-fd465ac8e81a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   pclass  age  sibsp  parch      fare  sex_female  sex_male  embarked_C  \\\n",
            "0       1   29      0      0  211.3375           1         0           0   \n",
            "1       1    0      1      2  151.5500           0         1           0   \n",
            "2       1    2      1      2  151.5500           1         0           0   \n",
            "3       1   30      1      2  151.5500           0         1           0   \n",
            "4       1   25      1      2  151.5500           1         0           0   \n",
            "\n",
            "   embarked_Q  embarked_S  \n",
            "0           0           1  \n",
            "1           0           1  \n",
            "2           0           1  \n",
            "3           0           1  \n",
            "4           0           1  \n",
            "[29.68525592 33.29547928]\n",
            "(1047, 10)\n",
            "[[ 2.          0.3346087   1.         ...  0.          0.\n",
            "   1.        ]\n",
            " [ 2.         -0.44089198  0.         ...  0.          0.\n",
            "   1.        ]\n",
            " [ 3.         -0.28579185  0.         ...  0.          1.\n",
            "   0.        ]\n",
            " ...\n",
            " [ 2.          0.3346087   0.         ...  0.          0.\n",
            "   1.        ]\n",
            " [ 3.         -2.14699347  4.         ...  0.          0.\n",
            "   1.        ]\n",
            " [ 2.         -2.30209361  1.         ...  0.          0.\n",
            "   1.        ]]\n",
            "(1047,)\n",
            "[0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 1\n",
            " 1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0\n",
            " 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1\n",
            " 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1\n",
            " 0 1 0 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0\n",
            " 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0\n",
            " 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0\n",
            " 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "conjunto_entrenamiento = TensorDataset( torch.tensor(X_entrenamiento).float(), torch.tensor(y_entrenamiento).float())\n",
        "\n",
        "conjunto_prueba = TensorDataset( torch.tensor(X_prueba).float(),  torch.tensor(y_prueba).float())\n",
        "\n",
        "data_por_lote_entrenamiento=DataLoader(conjunto_entrenamiento,batch_size=10,shuffle=True)\n",
        "\n",
        "data_por_por_lote_test=DataLoader(conjunto_prueba,batch_size=10,shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "#datos_features_train,datos_label_train=next(iter(data_por_lote_entrenamiento))\n",
        "\n",
        "#datos_features_test,datos_label_test=next(iter(data_por_por_lote_test))\n",
        "\n",
        "\n",
        "print(data_por_lote_entrenamiento.batch_size)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2jQ67LCbKprh",
        "outputId": "956d17fe-a3a5-4a62-8be3-2d94991ba87c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "modelo=torch.Sequential(\n",
        "\n",
        "                        torch.nn.Linear(input_size,3),\n",
        "                        torch.nn.ReLU(),\n",
        "\n",
        "                        torch.nn.Linear(3,4),\n",
        "                        torch.nn.ReLU(),\n",
        "\n",
        "                        torch.nn.Linear(4,1),\n",
        "                        torch.nn.Sigmoid()\n",
        ")"
      ],
      "metadata": {
        "id": "7WMFZMRih-Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "class PerceptronMulticapa(nn.Module):\n",
        "\n",
        "   def __init__(self,input_size):\n",
        "    super(PerceptronMulticapa,self).__init__()\n",
        "    print(input_size)\n",
        "\n",
        "    self.fc1=nn.Linear(input_size,3)\n",
        "\n",
        "    self.fc2=nn.Linear(3,4)\n",
        "\n",
        "    self.capa_salida =nn.Linear(4,1)\n",
        "\n",
        "   def forward(self,x):\n",
        "\n",
        "     x=self.fc1(x)\n",
        "     x=F.relu(x)\n",
        "\n",
        "     x=self.fc2(x)\n",
        "     x=F.relu(x)\n",
        "\n",
        "     output=self.capa_salida(x)\n",
        "\n",
        "\n",
        "\n",
        "     return output\n"
      ],
      "metadata": {
        "id": "pPePfzy31mvx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA está disponible.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"CUDA no está disponible. Se utilizará la CPU.\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "xwtxORPcuDNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14502c06-a471-47e3-b393-05e64a413058"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA está disponible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "#funcion clasificador:\n",
        "def clasificador(y_pred_test):\n",
        "\n",
        "  umbral = 0.6\n",
        "  y_pred_test_binario = (y_pred_test >= umbral).to(torch.float32)\n",
        "  return y_pred_test_binario\n",
        "\n",
        "#funcion acutity:\n",
        "\n",
        "def accuracy(y_test, y_real):\n",
        "    correctos = torch.sum(y_test == y_real).item()\n",
        "\n",
        "    return (correctos / len(y_test))\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "\n",
        "def TrainMLP(modelo,epochs,optimisador,criterio,input_size,data_Loader_entrenamiento,data_Loader_test):\n",
        "\n",
        " for epoch in range(epochs):\n",
        "\n",
        "  total_train_loss = 0.0\n",
        "  num_train_batches = len(data_Loader_entrenamiento)\n",
        "  modelo.train()\n",
        "\n",
        "  for x_entrenamiento,y_entrenamiento in (data_Loader_entrenamiento):\n",
        "   x_entrenamiento,y_entrenamiento=x_entrenamiento.to(device),y_entrenamiento.to(device)\n",
        "\n",
        "   y_predict=modelo(x_entrenamiento)\n",
        "\n",
        "   loss=criterio(y_predict,y_entrenamiento.view(-1,1))\n",
        "\n",
        "   loss.backward()\n",
        "   optimisador.step()\n",
        "   optimisador.zero_grad()\n",
        "   total_train_loss+=loss.item()\n",
        "\n",
        "  modelo.eval()\n",
        "  with torch.no_grad():\n",
        "    total_test_accuracy = 0.0\n",
        "    num_test_batches = len(data_Loader_test)\n",
        "\n",
        "    for X_prueba,y_prueba in (data_Loader_test):\n",
        "\n",
        "     X_prueba,y_prueba=X_prueba.to(device),y_prueba.to(device)\n",
        "     y_predict_test=modelo(X_prueba)\n",
        "     y_predict_test_p=torch.sigmoid(y_predict_test)\n",
        "     y_predic_test_clasificado=clasificador(y_predict_test_p)\n",
        "     Precision=accuracy(y_predic_test_clasificado,y_prueba.view(-1,1))\n",
        "     total_test_accuracy += Precision\n",
        "\n",
        "  avg_test_accuracy = (total_test_accuracy / num_test_batches)\n",
        "  avg_train_loss=(total_train_loss/num_train_batches)\n",
        "  print(f'Epoca[{epoch+1}], Perdida: {avg_train_loss:.4f},Accuryty:{avg_test_accuracy:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "\n",
        "input_sizes=10\n",
        "\n",
        "PerceptronMulti=PerceptronMulticapa(input_sizes)\n",
        "\n",
        "criterios=nn.BCEWithLogitsLoss() # automaticamente aplica el sigmoide a la capa de salida y clasfica 0 -1 para el loss\n",
        "\n",
        "optimizer=optim.SGD(PerceptronMulti.parameters(),lr=0.01)\n",
        "\n",
        "epocas=500\n",
        "\n",
        "PerceptronMulti=PerceptronMulti.to(device)\n",
        "\n",
        "TrainMLP(PerceptronMulti,epocas,optimizer,criterios,input_sizes,data_por_lote_entrenamiento,data_por_por_lote_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eb2AfYxQchgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nuevo datos:\n",
        "\n",
        "\n",
        "nuevo_x=[[1,85,0,0,55.155,0,0,0,1,0]]\n",
        "\n",
        "coulmans=[1,4]\n",
        "data_x_normalizada,_,_=normalizar_datos(nuevo_x,coulmans,mean_,std_)\n",
        "\n",
        "nuevo_X_transform=torch.from_numpy(data_x_normalizada.transform(nuevo_x)).float()\n",
        "print(nuevo_X_transform)\n",
        "y_predict=PerceptronMulti(nuevo_X_transform)\n",
        "\n",
        "print(clasificador(y_predict))\n",
        "\n"
      ],
      "metadata": {
        "id": "X8ZpEP6be9hg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "f27df886-1187-4170-95cc-55d905b2e3d3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-ecc8f9c596b3>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcoulmans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata_x_normalizada\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalizar_datos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnuevo_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoulmans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnuevo_X_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x_normalizada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnuevo_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-745757d9d9cb>\u001b[0m in \u001b[0;36mnormalizar_datos\u001b[0;34m(data, columnas_no_cat, mean_value_continuos, std_value_continuos)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalizar_datos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumnas_no_cat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_value_continuos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd_value_continuos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m  \u001b[0mdatos_continuos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumnas_no_cat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#tomaremos los datos de nuestro dataset de esas columnas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m  \u001b[0;32mif\u001b[0m \u001b[0mmean_value_continuos\u001b[0m \u001b[0;32mis\u001b[0m  \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "y_pred_multiclases = torch.tensor([[0.1, 1.8, 0.8, 0.4, 2],\n",
        "                                   [0.5, 2, 3.5, 5, 2.1]])\n",
        "\n",
        "def clasificador(y_pred_test):\n",
        "\n",
        "   max_values_tensor = torch.empty((0,), dtype=torch.float32)\n",
        "\n",
        "   for tensor in y_pred_test:\n",
        "\n",
        "     max_values, max_indices  = torch.max(tensor, dim=0)\n",
        "\n",
        "     max_values_tensor = torch.cat((max_values_tensor, max_indices.unsqueeze(0)))\n",
        "\n",
        "   return max_values_tensor\n",
        "\n",
        "print(clasificador(y_pred_multiclases))\n"
      ],
      "metadata": {
        "id": "7LqpXE2_9vpy",
        "outputId": "c10e4aa3-a539-4e8d-df5a-8dfd2f076f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4., 3.])\n"
          ]
        }
      ]
    }
  ]
}