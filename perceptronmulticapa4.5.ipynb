{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuniorHZ19/ML/blob/main/perceptronmulticapa4.5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nEH5XojTlDKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec238a7d-ac27-4b0d-c1f2-1dd873d992a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "class MiDataSet(Dataset):\n",
        "\n",
        "  def __init__(self,csv_file):\n",
        "\n",
        "     data=pd.read_csv(csv_file)\n",
        "\n",
        "     self.x,self.y= self.limpiezaDatos(data)\n",
        "\n",
        "     self.samples=self.y.shape[0]\n",
        "\n",
        "\n",
        "  def __getitem__(self,id):\n",
        "\n",
        "   return self.x[id],self.y[id]\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "   return self.samples\n",
        "\n",
        "\n",
        "  def limpiezaDatos(self,data):\n",
        "\n",
        "    data=data.dropna(how=\"all\")\n",
        "\n",
        "    data=data.drop_duplicates()\n",
        "\n",
        "    data=data.drop(columns=[\"name\",\"ticket\",\"cabin\",\"boat\",\"body\",\"home.dest\"])\n",
        "\n",
        "    data[[\"age\",\"fare\"]]=data[[\"age\",\"fare\"]].fillna(data[[\"age\",\"fare\"]].mean())\n",
        "\n",
        "    data[\"embarked\"]=data[\"embarked\"].fillna(\"S\")\n",
        "\n",
        "    data[\"age\"]=data[\"age\"].astype(int)\n",
        "\n",
        "    data=pd.get_dummies (data,columns=[\"sex\",\"embarked\"],prefix=[\"sex\",\"embarked\"])\n",
        "\n",
        "    variables_x=data.drop(columns=[\"survived\"])\n",
        "\n",
        "    print(variables_x.head())\n",
        "\n",
        "    print(data[\"survived\"].head())\n",
        "    self.scaler=StandardScaler()\n",
        "\n",
        "    variables_x_esclados=self.scaler.fit_transform(variables_x)\n",
        "\n",
        "    variable_y=data[\"survived\"].values\n",
        "\n",
        "\n",
        "    datos_x=torch.from_numpy(variables_x_esclados).float()\n",
        "\n",
        "    datos_y=torch.from_numpy(variable_y).float()\n",
        "\n",
        "\n",
        "\n",
        "    return datos_x,  datos_y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S7i_BABFA3pQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "mis_datos=MiDataSet(\"/content/titanic.csv\")\n",
        "\n",
        "\n",
        "\n",
        "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(mis_datos.x, mis_datos.y, test_size=0.3, random_state=0,stratify=mis_datos.y)\n",
        "\n",
        "print(X_entrenamiento.shape)\n",
        "\n",
        "print(X_prueba)\n",
        "\n",
        "print(y_entrenamiento.shape)\n",
        "\n",
        "print(y_prueba)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zOqxrfSRJivq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39cd93d-1198-465d-a576-653a42f02364"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   pclass  age  sibsp  parch      fare  sex_female  sex_male  embarked_C  \\\n",
            "0       1   29      0      0  211.3375           1         0           0   \n",
            "1       1    0      1      2  151.5500           0         1           0   \n",
            "2       1    2      1      2  151.5500           1         0           0   \n",
            "3       1   30      1      2  151.5500           0         1           0   \n",
            "4       1   25      1      2  151.5500           1         0           0   \n",
            "\n",
            "   embarked_Q  embarked_S  \n",
            "0           0           1  \n",
            "1           0           1  \n",
            "2           0           1  \n",
            "3           0           1  \n",
            "4           0           1  \n",
            "0    1\n",
            "1    1\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: survived, dtype: int64\n",
            "torch.Size([916, 10])\n",
            "tensor([[ 0.8419, -0.5960, -0.4791,  ..., -0.5098, -0.3220,  0.6550],\n",
            "        [-1.5461,  1.3428, -0.4791,  ..., -0.5098, -0.3220,  0.6550],\n",
            "        [ 0.8419, -1.8368,  2.4020,  ..., -0.5098, -0.3220,  0.6550],\n",
            "        ...,\n",
            "        [-0.3521,  3.1264, -0.4791,  ..., -0.5098, -0.3220,  0.6550],\n",
            "        [ 0.8419,  0.7999,  0.4813,  ..., -0.5098, -0.3220,  0.6550],\n",
            "        [ 0.8419,  0.4122, -0.4791,  ...,  1.9617, -0.3220, -1.5267]])\n",
            "torch.Size([916])\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
            "        1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
            "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
            "        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
            "        0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
            "        0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
            "        0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
            "        0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
            "        1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
            "        0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
            "        1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "conjunto_entrenamiento = TensorDataset(X_entrenamiento, y_entrenamiento)\n",
        "\n",
        "conjunto_prueba = TensorDataset(X_prueba, y_prueba)\n",
        "\n",
        "\n",
        "\n",
        "data_por_lote_entrenamiento=DataLoader(conjunto_entrenamiento,batch_size=10,shuffle=True)\n",
        "\n",
        "data_por_por_lote_test=DataLoader(conjunto_prueba,batch_size=10,shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "#datos_features_train,datos_label_train=next(iter(data_por_lote_entrenamiento))\n",
        "\n",
        "#datos_features_test,datos_label_test=next(iter(data_por_por_lote_test))\n",
        "\n",
        "\n",
        "print(data_por_lote_entrenamiento.batch_size)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2jQ67LCbKprh",
        "outputId": "d40eaa61-b51f-4207-ccca-43c5533e274b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "modelo=torch.Sequential(\n",
        "\n",
        "                        torch.nn.Linear(input_size,3),\n",
        "                        torch.nn.ReLU(),\n",
        "\n",
        "                        torch.nn.Linear(3,4),\n",
        "                        torch.nn.ReLU(),\n",
        "\n",
        "                        torch.nn.Linear(4,1),\n",
        "                        torch.nn.Sigmoid()\n",
        ")"
      ],
      "metadata": {
        "id": "7WMFZMRih-Tv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "ce3ef148-3853-453d-bcd4-2c2ab5c7172e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-aa34abe5cb9d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m modelo=torch.Sequential(\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1833\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module '{__name__}' has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'Sequential'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "class PerceptronMulticapa(nn.Module):\n",
        "\n",
        "   def __init__(self,input_size):\n",
        "    super(PerceptronMulticapa,self).__init__()\n",
        "\n",
        "    self.capa_oculta1=nn.Linear(input_size,100)\n",
        "\n",
        "    self.capa_oculta2=nn.Linear(100,50)\n",
        "\n",
        "    self.capa_oculta3=nn.Linear(50,20)\n",
        "\n",
        "    self.capa_salida =nn.Linear(20,1)\n",
        "\n",
        "   def forward(self,x):\n",
        "\n",
        "     x=self.capa_oculta1(x)\n",
        "     x=F.relu(x)\n",
        "\n",
        "     x=self.capa_oculta2(x)\n",
        "     x=F.relu(x)\n",
        "\n",
        "     x=self.capa_oculta3(x)\n",
        "     x=F.relu(x)\n",
        "\n",
        "     x=self.capa_salida(x)\n",
        "     output=torch.sigmoid(x)\n",
        "\n",
        "\n",
        "     return output\n"
      ],
      "metadata": {
        "id": "pPePfzy31mvx"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA está disponible.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"CUDA no está disponible. Se utilizará la CPU.\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "xwtxORPcuDNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6ae20e-d03b-42f1-9572-61b88f87aecb"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA está disponible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#funcion clasificador:\n",
        "def clasificador(y_pred_test):\n",
        "\n",
        "  umbral = 0.6\n",
        "  y_pred_test_binario = (y_pred_test >= umbral).to(torch.float32)\n",
        "\n",
        "  return y_pred_test_binario\n",
        "\n",
        "#funcion acutity:\n",
        "def accurity(y_test,y_real):\n",
        "   correctos=0\n",
        "   for predicho, real in zip(y_test, y_real):\n",
        "    if predicho==real:\n",
        "     correctos+=1\n",
        "   return correctos/len(y_test)\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "\n",
        "def TrainMLP(modelo,epochs,optimisador,criterio,input_size,data_por_lote_entrenamiento,data_por_por_lote_test):\n",
        "\n",
        " for epoch in range(epochs):\n",
        "\n",
        "  total_train_loss = 0.0\n",
        "  num_train_batches = len(data_por_lote_entrenamiento)\n",
        "  modelo.train()\n",
        "\n",
        "  for x_entrenamiento,y_entrenamiento in (data_por_lote_entrenamiento):\n",
        "   x_entrenamiento,y_entrenamiento=x_entrenamiento.to(device),y_entrenamiento.to(device)\n",
        "\n",
        "   y_predict=modelo(x_entrenamiento)\n",
        "   loss=criterio(y_predict,y_entrenamiento.view(-1,1))\n",
        "\n",
        "   loss.backward()\n",
        "   optimisador.step()\n",
        "   optimisador.zero_grad()\n",
        "   total_train_loss+=loss.item()\n",
        "\n",
        "  modelo.eval()\n",
        "  with torch.no_grad():\n",
        "    total_test_accuracy = 0.0\n",
        "    num_test_batches = len(data_por_por_lote_test)\n",
        "\n",
        "    for X_prueba,y_prueba in (data_por_por_lote_test):\n",
        "\n",
        "     X_prueba,y_prueba=X_prueba.to(device),y_prueba.to(device)\n",
        "     y_predict_test=modelo(X_prueba)\n",
        "     y_predic_test_clasificado=clasificador(y_predict_test)\n",
        "     Precision=accurity(y_prueba,y_predic_test_clasificado)\n",
        "     total_test_accuracy += Precision\n",
        "  avg_test_accuracy = total_test_accuracy / num_test_batches\n",
        "  avg_train_loss=total_train_loss/num_train_batches\n",
        "  print(f'Epoca[{epoch+1}], Perdida: {avg_train_loss:.4f},Accuryty:{avg_test_accuracy:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "\n",
        "input_sizes=10\n",
        "\n",
        "PerceptronMulti=PerceptronMulticapa(input_sizes)\n",
        "\n",
        "criterios=nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer=optim.Adam(PerceptronMulti.parameters(),lr=0.001)\n",
        "\n",
        "epocas=8500\n",
        "\n",
        "PerceptronMulti=PerceptronMulti.to(device)\n",
        "\n",
        "TrainMLP(PerceptronMulti,epocas,optimizer,criterios,input_sizes,data_por_lote_entrenamiento,data_por_por_lote_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#nuevo datos:\n",
        "\n",
        "def escalarNuevaData(data):\n",
        "\n",
        "    scaler=StandardScaler()\n",
        "\n",
        "    datos_escalados=scaler.fit_transform(data)\n",
        "\n",
        "    datos_x_tensor=torch.from_numpy(datos_escalados).float()\n",
        "\n",
        "    return datos_x_tensor\n",
        "\n",
        "nuevo_x=escalarNuevaData([[1,29,0,0,211,1,0,0,0,1]])\n",
        "\n",
        "y_predict=PerceptronMulti(nuevo_x)\n",
        "\n",
        "print(clasificador(y_predict))\n",
        "\n"
      ],
      "metadata": {
        "id": "eb2AfYxQchgT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8d66d14a-88bd-4d31-fc0b-47db44dab397"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca[1], Perdida: 0.7127,Accuryty:0.7550\n",
            "Epoca[2], Perdida: 0.6427,Accuryty:0.8075\n",
            "Epoca[3], Perdida: 0.6349,Accuryty:0.8150\n",
            "Epoca[4], Perdida: 0.6349,Accuryty:0.8067\n",
            "Epoca[5], Perdida: 0.6322,Accuryty:0.7917\n",
            "Epoca[6], Perdida: 0.6331,Accuryty:0.8000\n",
            "Epoca[7], Perdida: 0.6320,Accuryty:0.7975\n",
            "Epoca[8], Perdida: 0.6297,Accuryty:0.7875\n",
            "Epoca[9], Perdida: 0.6294,Accuryty:0.7992\n",
            "Epoca[10], Perdida: 0.6289,Accuryty:0.7900\n",
            "Epoca[11], Perdida: 0.6321,Accuryty:0.8050\n",
            "Epoca[12], Perdida: 0.6304,Accuryty:0.7867\n",
            "Epoca[13], Perdida: 0.6300,Accuryty:0.7950\n",
            "Epoca[14], Perdida: 0.6305,Accuryty:0.7925\n",
            "Epoca[15], Perdida: 0.6293,Accuryty:0.7867\n",
            "Epoca[16], Perdida: 0.6287,Accuryty:0.8125\n",
            "Epoca[17], Perdida: 0.6307,Accuryty:0.8100\n",
            "Epoca[18], Perdida: 0.6283,Accuryty:0.8000\n",
            "Epoca[19], Perdida: 0.6282,Accuryty:0.7858\n",
            "Epoca[20], Perdida: 0.6273,Accuryty:0.7917\n",
            "Epoca[21], Perdida: 0.6282,Accuryty:0.7917\n",
            "Epoca[22], Perdida: 0.6290,Accuryty:0.7917\n",
            "Epoca[23], Perdida: 0.6276,Accuryty:0.7975\n",
            "Epoca[24], Perdida: 0.6286,Accuryty:0.7917\n",
            "Epoca[25], Perdida: 0.6282,Accuryty:0.7975\n",
            "Epoca[26], Perdida: 0.6293,Accuryty:0.8025\n",
            "Epoca[27], Perdida: 0.6292,Accuryty:0.7942\n",
            "Epoca[28], Perdida: 0.6291,Accuryty:0.7950\n",
            "Epoca[29], Perdida: 0.6284,Accuryty:0.8025\n",
            "Epoca[30], Perdida: 0.6265,Accuryty:0.8092\n",
            "Epoca[31], Perdida: 0.6261,Accuryty:0.8150\n",
            "Epoca[32], Perdida: 0.6276,Accuryty:0.7950\n",
            "Epoca[33], Perdida: 0.6290,Accuryty:0.8025\n",
            "Epoca[34], Perdida: 0.6298,Accuryty:0.8067\n",
            "Epoca[35], Perdida: 0.6276,Accuryty:0.7975\n",
            "Epoca[36], Perdida: 0.6287,Accuryty:0.7967\n",
            "Epoca[37], Perdida: 0.6269,Accuryty:0.8025\n",
            "Epoca[38], Perdida: 0.6263,Accuryty:0.7917\n",
            "Epoca[39], Perdida: 0.6278,Accuryty:0.7967\n",
            "Epoca[40], Perdida: 0.6272,Accuryty:0.8050\n",
            "Epoca[41], Perdida: 0.6260,Accuryty:0.7942\n",
            "Epoca[42], Perdida: 0.6251,Accuryty:0.8092\n",
            "Epoca[43], Perdida: 0.6274,Accuryty:0.7992\n",
            "Epoca[44], Perdida: 0.6268,Accuryty:0.8000\n",
            "Epoca[45], Perdida: 0.6257,Accuryty:0.7942\n",
            "Epoca[46], Perdida: 0.6250,Accuryty:0.7933\n",
            "Epoca[47], Perdida: 0.6270,Accuryty:0.8025\n",
            "Epoca[48], Perdida: 0.6260,Accuryty:0.7992\n",
            "Epoca[49], Perdida: 0.6269,Accuryty:0.7908\n",
            "Epoca[50], Perdida: 0.6260,Accuryty:0.8017\n",
            "Epoca[51], Perdida: 0.6260,Accuryty:0.7967\n",
            "Epoca[52], Perdida: 0.6261,Accuryty:0.8025\n",
            "Epoca[53], Perdida: 0.6262,Accuryty:0.7967\n",
            "Epoca[54], Perdida: 0.6257,Accuryty:0.7967\n",
            "Epoca[55], Perdida: 0.6260,Accuryty:0.7967\n",
            "Epoca[56], Perdida: 0.6255,Accuryty:0.7967\n",
            "Epoca[57], Perdida: 0.6251,Accuryty:0.7967\n",
            "Epoca[58], Perdida: 0.6271,Accuryty:0.8025\n",
            "Epoca[59], Perdida: 0.6251,Accuryty:0.7908\n",
            "Epoca[60], Perdida: 0.6255,Accuryty:0.8025\n",
            "Epoca[61], Perdida: 0.6256,Accuryty:0.8175\n",
            "Epoca[62], Perdida: 0.6265,Accuryty:0.8100\n",
            "Epoca[63], Perdida: 0.6276,Accuryty:0.8100\n",
            "Epoca[64], Perdida: 0.6261,Accuryty:0.8042\n",
            "Epoca[65], Perdida: 0.6278,Accuryty:0.8025\n",
            "Epoca[66], Perdida: 0.6260,Accuryty:0.7967\n",
            "Epoca[67], Perdida: 0.6252,Accuryty:0.7967\n",
            "Epoca[68], Perdida: 0.6255,Accuryty:0.8050\n",
            "Epoca[69], Perdida: 0.6241,Accuryty:0.8075\n",
            "Epoca[70], Perdida: 0.6254,Accuryty:0.8125\n",
            "Epoca[71], Perdida: 0.6247,Accuryty:0.8100\n",
            "Epoca[72], Perdida: 0.6252,Accuryty:0.8100\n",
            "Epoca[73], Perdida: 0.6245,Accuryty:0.8092\n",
            "Epoca[74], Perdida: 0.6236,Accuryty:0.8117\n",
            "Epoca[75], Perdida: 0.6232,Accuryty:0.8117\n",
            "Epoca[76], Perdida: 0.6237,Accuryty:0.8175\n",
            "Epoca[77], Perdida: 0.6223,Accuryty:0.8200\n",
            "Epoca[78], Perdida: 0.6228,Accuryty:0.8125\n",
            "Epoca[79], Perdida: 0.6219,Accuryty:0.8100\n",
            "Epoca[80], Perdida: 0.6218,Accuryty:0.8075\n",
            "Epoca[81], Perdida: 0.6210,Accuryty:0.8092\n",
            "Epoca[82], Perdida: 0.6209,Accuryty:0.8017\n",
            "Epoca[83], Perdida: 0.6224,Accuryty:0.8017\n",
            "Epoca[84], Perdida: 0.6212,Accuryty:0.8042\n",
            "Epoca[85], Perdida: 0.6224,Accuryty:0.7942\n",
            "Epoca[86], Perdida: 0.6237,Accuryty:0.8017\n",
            "Epoca[87], Perdida: 0.6214,Accuryty:0.8050\n",
            "Epoca[88], Perdida: 0.6219,Accuryty:0.7992\n",
            "Epoca[89], Perdida: 0.6211,Accuryty:0.8050\n",
            "Epoca[90], Perdida: 0.6209,Accuryty:0.8050\n",
            "Epoca[91], Perdida: 0.6213,Accuryty:0.7992\n",
            "Epoca[92], Perdida: 0.6207,Accuryty:0.8017\n",
            "Epoca[93], Perdida: 0.6213,Accuryty:0.8017\n",
            "Epoca[94], Perdida: 0.6211,Accuryty:0.8075\n",
            "Epoca[95], Perdida: 0.6205,Accuryty:0.7933\n",
            "Epoca[96], Perdida: 0.6209,Accuryty:0.8017\n",
            "Epoca[97], Perdida: 0.6208,Accuryty:0.7958\n",
            "Epoca[98], Perdida: 0.6216,Accuryty:0.8125\n",
            "Epoca[99], Perdida: 0.6223,Accuryty:0.8075\n",
            "Epoca[100], Perdida: 0.6213,Accuryty:0.8125\n",
            "Epoca[101], Perdida: 0.6221,Accuryty:0.8075\n",
            "Epoca[102], Perdida: 0.6237,Accuryty:0.7958\n",
            "Epoca[103], Perdida: 0.6219,Accuryty:0.8150\n",
            "Epoca[104], Perdida: 0.6221,Accuryty:0.7958\n",
            "Epoca[105], Perdida: 0.6214,Accuryty:0.8075\n",
            "Epoca[106], Perdida: 0.6213,Accuryty:0.8075\n",
            "Epoca[107], Perdida: 0.6211,Accuryty:0.8075\n",
            "Epoca[108], Perdida: 0.6213,Accuryty:0.7958\n",
            "Epoca[109], Perdida: 0.6227,Accuryty:0.8075\n",
            "Epoca[110], Perdida: 0.6216,Accuryty:0.8075\n",
            "Epoca[111], Perdida: 0.6217,Accuryty:0.8075\n",
            "Epoca[112], Perdida: 0.6212,Accuryty:0.8075\n",
            "Epoca[113], Perdida: 0.6208,Accuryty:0.7992\n",
            "Epoca[114], Perdida: 0.6220,Accuryty:0.8125\n",
            "Epoca[115], Perdida: 0.6229,Accuryty:0.8125\n",
            "Epoca[116], Perdida: 0.6220,Accuryty:0.8100\n",
            "Epoca[117], Perdida: 0.6220,Accuryty:0.7983\n",
            "Epoca[118], Perdida: 0.6215,Accuryty:0.8025\n",
            "Epoca[119], Perdida: 0.6224,Accuryty:0.7958\n",
            "Epoca[120], Perdida: 0.6207,Accuryty:0.7958\n",
            "Epoca[121], Perdida: 0.6212,Accuryty:0.8075\n",
            "Epoca[122], Perdida: 0.6208,Accuryty:0.8075\n",
            "Epoca[123], Perdida: 0.6225,Accuryty:0.8067\n",
            "Epoca[124], Perdida: 0.6218,Accuryty:0.8017\n",
            "Epoca[125], Perdida: 0.6212,Accuryty:0.7958\n",
            "Epoca[126], Perdida: 0.6216,Accuryty:0.8075\n",
            "Epoca[127], Perdida: 0.6230,Accuryty:0.8042\n",
            "Epoca[128], Perdida: 0.6249,Accuryty:0.8067\n",
            "Epoca[129], Perdida: 0.6233,Accuryty:0.7967\n",
            "Epoca[130], Perdida: 0.6222,Accuryty:0.8067\n",
            "Epoca[131], Perdida: 0.6220,Accuryty:0.8050\n",
            "Epoca[132], Perdida: 0.6218,Accuryty:0.8050\n",
            "Epoca[133], Perdida: 0.6220,Accuryty:0.8017\n",
            "Epoca[134], Perdida: 0.6211,Accuryty:0.8067\n",
            "Epoca[135], Perdida: 0.6217,Accuryty:0.8050\n",
            "Epoca[136], Perdida: 0.6211,Accuryty:0.8042\n",
            "Epoca[137], Perdida: 0.6214,Accuryty:0.7992\n",
            "Epoca[138], Perdida: 0.6226,Accuryty:0.8025\n",
            "Epoca[139], Perdida: 0.6230,Accuryty:0.8017\n",
            "Epoca[140], Perdida: 0.6224,Accuryty:0.8042\n",
            "Epoca[141], Perdida: 0.6213,Accuryty:0.7875\n",
            "Epoca[142], Perdida: 0.6214,Accuryty:0.8050\n",
            "Epoca[143], Perdida: 0.6214,Accuryty:0.7992\n",
            "Epoca[144], Perdida: 0.6213,Accuryty:0.7992\n",
            "Epoca[145], Perdida: 0.6213,Accuryty:0.7933\n",
            "Epoca[146], Perdida: 0.6214,Accuryty:0.8050\n",
            "Epoca[147], Perdida: 0.6219,Accuryty:0.7933\n",
            "Epoca[148], Perdida: 0.6217,Accuryty:0.8050\n",
            "Epoca[149], Perdida: 0.6214,Accuryty:0.7992\n",
            "Epoca[150], Perdida: 0.6216,Accuryty:0.7992\n",
            "Epoca[151], Perdida: 0.6215,Accuryty:0.7933\n",
            "Epoca[152], Perdida: 0.6213,Accuryty:0.8050\n",
            "Epoca[153], Perdida: 0.6212,Accuryty:0.7875\n",
            "Epoca[154], Perdida: 0.6213,Accuryty:0.7875\n",
            "Epoca[155], Perdida: 0.6212,Accuryty:0.8050\n",
            "Epoca[156], Perdida: 0.6229,Accuryty:0.7908\n",
            "Epoca[157], Perdida: 0.6213,Accuryty:0.8017\n",
            "Epoca[158], Perdida: 0.6221,Accuryty:0.7992\n",
            "Epoca[159], Perdida: 0.6222,Accuryty:0.7958\n",
            "Epoca[160], Perdida: 0.6215,Accuryty:0.8150\n",
            "Epoca[161], Perdida: 0.6217,Accuryty:0.8075\n",
            "Epoca[162], Perdida: 0.6210,Accuryty:0.8042\n",
            "Epoca[163], Perdida: 0.6220,Accuryty:0.8100\n",
            "Epoca[164], Perdida: 0.6216,Accuryty:0.8075\n",
            "Epoca[165], Perdida: 0.6226,Accuryty:0.7992\n",
            "Epoca[166], Perdida: 0.6215,Accuryty:0.8050\n",
            "Epoca[167], Perdida: 0.6240,Accuryty:0.7992\n",
            "Epoca[168], Perdida: 0.6221,Accuryty:0.8025\n",
            "Epoca[169], Perdida: 0.6214,Accuryty:0.7992\n",
            "Epoca[170], Perdida: 0.6210,Accuryty:0.7967\n",
            "Epoca[171], Perdida: 0.6226,Accuryty:0.7967\n",
            "Epoca[172], Perdida: 0.6223,Accuryty:0.8125\n",
            "Epoca[173], Perdida: 0.6208,Accuryty:0.8017\n",
            "Epoca[174], Perdida: 0.6211,Accuryty:0.8017\n",
            "Epoca[175], Perdida: 0.6209,Accuryty:0.8075\n",
            "Epoca[176], Perdida: 0.6211,Accuryty:0.8017\n",
            "Epoca[177], Perdida: 0.6209,Accuryty:0.8075\n",
            "Epoca[178], Perdida: 0.6207,Accuryty:0.8017\n",
            "Epoca[179], Perdida: 0.6208,Accuryty:0.8050\n",
            "Epoca[180], Perdida: 0.6208,Accuryty:0.8017\n",
            "Epoca[181], Perdida: 0.6215,Accuryty:0.8050\n",
            "Epoca[182], Perdida: 0.6216,Accuryty:0.8017\n",
            "Epoca[183], Perdida: 0.6209,Accuryty:0.8075\n",
            "Epoca[184], Perdida: 0.6211,Accuryty:0.8017\n",
            "Epoca[185], Perdida: 0.6211,Accuryty:0.8017\n",
            "Epoca[186], Perdida: 0.6217,Accuryty:0.8017\n",
            "Epoca[187], Perdida: 0.6217,Accuryty:0.8075\n",
            "Epoca[188], Perdida: 0.6210,Accuryty:0.8017\n",
            "Epoca[189], Perdida: 0.6213,Accuryty:0.8075\n",
            "Epoca[190], Perdida: 0.6213,Accuryty:0.8017\n",
            "Epoca[191], Perdida: 0.6214,Accuryty:0.8042\n",
            "Epoca[192], Perdida: 0.6207,Accuryty:0.8075\n",
            "Epoca[193], Perdida: 0.6211,Accuryty:0.8008\n",
            "Epoca[194], Perdida: 0.6213,Accuryty:0.8017\n",
            "Epoca[195], Perdida: 0.6213,Accuryty:0.8100\n",
            "Epoca[196], Perdida: 0.6241,Accuryty:0.8117\n",
            "Epoca[197], Perdida: 0.6233,Accuryty:0.8117\n",
            "Epoca[198], Perdida: 0.6228,Accuryty:0.8125\n",
            "Epoca[199], Perdida: 0.6236,Accuryty:0.8175\n",
            "Epoca[200], Perdida: 0.6249,Accuryty:0.8150\n",
            "Epoca[201], Perdida: 0.6227,Accuryty:0.8092\n",
            "Epoca[202], Perdida: 0.6231,Accuryty:0.8075\n",
            "Epoca[203], Perdida: 0.6228,Accuryty:0.8075\n",
            "Epoca[204], Perdida: 0.6215,Accuryty:0.8017\n",
            "Epoca[205], Perdida: 0.6221,Accuryty:0.8050\n",
            "Epoca[206], Perdida: 0.6221,Accuryty:0.7992\n",
            "Epoca[207], Perdida: 0.6219,Accuryty:0.8050\n",
            "Epoca[208], Perdida: 0.6217,Accuryty:0.8067\n",
            "Epoca[209], Perdida: 0.6224,Accuryty:0.8125\n",
            "Epoca[210], Perdida: 0.6221,Accuryty:0.8175\n",
            "Epoca[211], Perdida: 0.6231,Accuryty:0.8200\n",
            "Epoca[212], Perdida: 0.6228,Accuryty:0.8125\n",
            "Epoca[213], Perdida: 0.6218,Accuryty:0.8067\n",
            "Epoca[214], Perdida: 0.6224,Accuryty:0.8092\n",
            "Epoca[215], Perdida: 0.6223,Accuryty:0.8125\n",
            "Epoca[216], Perdida: 0.6223,Accuryty:0.8125\n",
            "Epoca[217], Perdida: 0.6221,Accuryty:0.8008\n",
            "Epoca[218], Perdida: 0.6224,Accuryty:0.8067\n",
            "Epoca[219], Perdida: 0.6219,Accuryty:0.8067\n",
            "Epoca[220], Perdida: 0.6220,Accuryty:0.8067\n",
            "Epoca[221], Perdida: 0.6220,Accuryty:0.8067\n",
            "Epoca[222], Perdida: 0.6223,Accuryty:0.8100\n",
            "Epoca[223], Perdida: 0.6223,Accuryty:0.8050\n",
            "Epoca[224], Perdida: 0.6230,Accuryty:0.7992\n",
            "Epoca[225], Perdida: 0.6229,Accuryty:0.7992\n",
            "Epoca[226], Perdida: 0.6215,Accuryty:0.8075\n",
            "Epoca[227], Perdida: 0.6219,Accuryty:0.8175\n",
            "Epoca[228], Perdida: 0.6228,Accuryty:0.8125\n",
            "Epoca[229], Perdida: 0.6209,Accuryty:0.8100\n",
            "Epoca[230], Perdida: 0.6216,Accuryty:0.8150\n",
            "Epoca[231], Perdida: 0.6214,Accuryty:0.8042\n",
            "Epoca[232], Perdida: 0.6215,Accuryty:0.8042\n",
            "Epoca[233], Perdida: 0.6215,Accuryty:0.8100\n",
            "Epoca[234], Perdida: 0.6209,Accuryty:0.8042\n",
            "Epoca[235], Perdida: 0.6210,Accuryty:0.8100\n",
            "Epoca[236], Perdida: 0.6219,Accuryty:0.8042\n",
            "Epoca[237], Perdida: 0.6209,Accuryty:0.8100\n",
            "Epoca[238], Perdida: 0.6207,Accuryty:0.7983\n",
            "Epoca[239], Perdida: 0.6215,Accuryty:0.8175\n",
            "Epoca[240], Perdida: 0.6219,Accuryty:0.8175\n",
            "Epoca[241], Perdida: 0.6220,Accuryty:0.8042\n",
            "Epoca[242], Perdida: 0.6211,Accuryty:0.8042\n",
            "Epoca[243], Perdida: 0.6211,Accuryty:0.7983\n",
            "Epoca[244], Perdida: 0.6223,Accuryty:0.8067\n",
            "Epoca[245], Perdida: 0.6217,Accuryty:0.8100\n",
            "Epoca[246], Perdida: 0.6210,Accuryty:0.8042\n",
            "Epoca[247], Perdida: 0.6212,Accuryty:0.8100\n",
            "Epoca[248], Perdida: 0.6221,Accuryty:0.8033\n",
            "Epoca[249], Perdida: 0.6220,Accuryty:0.8042\n",
            "Epoca[250], Perdida: 0.6214,Accuryty:0.8100\n",
            "Epoca[251], Perdida: 0.6211,Accuryty:0.8042\n",
            "Epoca[252], Perdida: 0.6217,Accuryty:0.8008\n",
            "Epoca[253], Perdida: 0.6206,Accuryty:0.8092\n",
            "Epoca[254], Perdida: 0.6212,Accuryty:0.8100\n",
            "Epoca[255], Perdida: 0.6210,Accuryty:0.8100\n",
            "Epoca[256], Perdida: 0.6217,Accuryty:0.8033\n",
            "Epoca[257], Perdida: 0.6217,Accuryty:0.7983\n",
            "Epoca[258], Perdida: 0.6206,Accuryty:0.8125\n",
            "Epoca[259], Perdida: 0.6211,Accuryty:0.8125\n",
            "Epoca[260], Perdida: 0.6214,Accuryty:0.8033\n",
            "Epoca[261], Perdida: 0.6223,Accuryty:0.8150\n",
            "Epoca[262], Perdida: 0.6226,Accuryty:0.8125\n",
            "Epoca[263], Perdida: 0.6228,Accuryty:0.8125\n",
            "Epoca[264], Perdida: 0.6225,Accuryty:0.8200\n",
            "Epoca[265], Perdida: 0.6222,Accuryty:0.8225\n",
            "Epoca[266], Perdida: 0.6210,Accuryty:0.8042\n",
            "Epoca[267], Perdida: 0.6206,Accuryty:0.7958\n",
            "Epoca[268], Perdida: 0.6208,Accuryty:0.7958\n",
            "Epoca[269], Perdida: 0.6213,Accuryty:0.8017\n",
            "Epoca[270], Perdida: 0.6208,Accuryty:0.8017\n",
            "Epoca[271], Perdida: 0.6217,Accuryty:0.8033\n",
            "Epoca[272], Perdida: 0.6222,Accuryty:0.8067\n",
            "Epoca[273], Perdida: 0.6211,Accuryty:0.8125\n",
            "Epoca[274], Perdida: 0.6211,Accuryty:0.8017\n",
            "Epoca[275], Perdida: 0.6205,Accuryty:0.8125\n",
            "Epoca[276], Perdida: 0.6214,Accuryty:0.8100\n",
            "Epoca[277], Perdida: 0.6217,Accuryty:0.7983\n",
            "Epoca[278], Perdida: 0.6210,Accuryty:0.7992\n",
            "Epoca[279], Perdida: 0.6203,Accuryty:0.8017\n",
            "Epoca[280], Perdida: 0.6197,Accuryty:0.8075\n",
            "Epoca[281], Perdida: 0.6211,Accuryty:0.8075\n",
            "Epoca[282], Perdida: 0.6215,Accuryty:0.8100\n",
            "Epoca[283], Perdida: 0.6200,Accuryty:0.8050\n",
            "Epoca[284], Perdida: 0.6201,Accuryty:0.7958\n",
            "Epoca[285], Perdida: 0.6211,Accuryty:0.8017\n",
            "Epoca[286], Perdida: 0.6211,Accuryty:0.8100\n",
            "Epoca[287], Perdida: 0.6216,Accuryty:0.8100\n",
            "Epoca[288], Perdida: 0.6215,Accuryty:0.8042\n",
            "Epoca[289], Perdida: 0.6214,Accuryty:0.8042\n",
            "Epoca[290], Perdida: 0.6210,Accuryty:0.7983\n",
            "Epoca[291], Perdida: 0.6218,Accuryty:0.8100\n",
            "Epoca[292], Perdida: 0.6210,Accuryty:0.8017\n",
            "Epoca[293], Perdida: 0.6215,Accuryty:0.8042\n",
            "Epoca[294], Perdida: 0.6205,Accuryty:0.8042\n",
            "Epoca[295], Perdida: 0.6213,Accuryty:0.8092\n",
            "Epoca[296], Perdida: 0.6211,Accuryty:0.8042\n",
            "Epoca[297], Perdida: 0.6214,Accuryty:0.8067\n",
            "Epoca[298], Perdida: 0.6214,Accuryty:0.8042\n",
            "Epoca[299], Perdida: 0.6210,Accuryty:0.7925\n",
            "Epoca[300], Perdida: 0.6203,Accuryty:0.8125\n",
            "Epoca[301], Perdida: 0.6218,Accuryty:0.8067\n",
            "Epoca[302], Perdida: 0.6220,Accuryty:0.7983\n",
            "Epoca[303], Perdida: 0.6216,Accuryty:0.8017\n",
            "Epoca[304], Perdida: 0.6206,Accuryty:0.8100\n",
            "Epoca[305], Perdida: 0.6214,Accuryty:0.8042\n",
            "Epoca[306], Perdida: 0.6216,Accuryty:0.8100\n",
            "Epoca[307], Perdida: 0.6206,Accuryty:0.8100\n",
            "Epoca[308], Perdida: 0.6202,Accuryty:0.8150\n",
            "Epoca[309], Perdida: 0.6208,Accuryty:0.8100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-330eaff38384>\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mPerceptronMulti\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPerceptronMulti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mTrainMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPerceptronMulti\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepocas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterios\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_por_lote_entrenamiento\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_por_por_lote_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-103-330eaff38384>\u001b[0m in \u001b[0;36mTrainMLP\u001b[0;34m(modelo, epochs, optimisador, criterio, input_size, data_por_lote_entrenamiento, data_por_por_lote_test)\u001b[0m\n\u001b[1;32m     31\u001b[0m    \u001b[0mx_entrenamiento\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_entrenamiento\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_entrenamiento\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_entrenamiento\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m    \u001b[0my_predict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_entrenamiento\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m    \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_entrenamiento\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-102-9e460ea0b177>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m      \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapa_oculta1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m      \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X8ZpEP6be9hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "y_pred_multiclases = torch.tensor([[0.1, 1.8, 0.8, 0.4, 2],\n",
        "                                   [0.5, 2, 3.5, 5, 2.1]])\n",
        "\n",
        "def clasificador(y_pred_test):\n",
        "\n",
        "   max_values_tensor = torch.empty((0,), dtype=torch.float32)\n",
        "\n",
        "   for tensor in y_pred_test:\n",
        "\n",
        "     max_values, max_indices  = torch.max(tensor, dim=0)\n",
        "\n",
        "     max_values_tensor = torch.cat((max_values_tensor, max_indices.unsqueeze(0)))\n",
        "\n",
        "   return max_values_tensor\n",
        "\n",
        "print(clasificador(y_pred_multiclases))\n"
      ],
      "metadata": {
        "id": "7LqpXE2_9vpy",
        "outputId": "c10e4aa3-a539-4e8d-df5a-8dfd2f076f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4., 3.])\n"
          ]
        }
      ]
    }
  ]
}