{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+v3CMwplCUwaksNk4OjXY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuniorHZ19/ML/blob/main/convolucionmejroar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEH5XojTlDKd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # *0) ** Instalando libreria(OBLIGATORIO)\n",
        "\n",
        "!pip install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *1) ** Descargando DataSet  de perros y gatos(OBLIGATORIO)\n",
        "import zipfile\n",
        "\n",
        "nombre_zip=\"data_set_dogcat.zip\"\n",
        "\n",
        "directorio_destino=\"/content/\"\n",
        "\n",
        "!gdown --id 19u9sy2053Ds739lyYSJut6S_k54trLnd -O {nombre_zip}\n",
        "\n",
        "with zipfile.ZipFile(nombre_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directorio_destino)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AKXCF3sFt24u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *1) ** Creacion de el csv de los path y clases(OBLIGATORIO)\n",
        "import os\n",
        "import pandas as pd\n",
        "def crear_paths_csv(directorio_base,clases_lista,clases,nombre_archivo):\n",
        "\n",
        "   columnas=[\"path\",\"etiqueta\"]\n",
        "   datos_csv=[]\n",
        "\n",
        "   for dir_base,dir,clase in  zip(directorio_base,clases_lista,clases):\n",
        "\n",
        "    for path  in (dir):\n",
        "\n",
        "     datos_csv.append([dir_base+path ,clase])\n",
        "\n",
        "\n",
        "   df_lista=pd.DataFrame(datos_csv,columns=columnas)\n",
        "   df_lista.to_csv(nombre_archivo,index=False)\n",
        "   print(\"Csv Creado\")\n",
        "\n",
        "directorio_gato=\"/content/PetImages/Cat/\"\n",
        "directorio_perro=\"/content/PetImages/Dog/\"\n",
        "\n",
        "gato_lista=os.listdir(directorio_gato)\n",
        "perro_list=os.listdir(directorio_perro)\n",
        "\n",
        "crear_paths_csv([directorio_gato,directorio_perro],[gato_lista,perro_list],[0,1],\"Data_set_paths.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUHILHof1EEC",
        "outputId": "8d2a8df2-ac2a-42cd-a212-870cd49980c4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Csv Creado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *2) ** Creacion de clase DATASET(OBLIGATORIO)\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class MiDataSet(Dataset):\n",
        "\n",
        "  def __init__(self,csv_file, transform=None):\n",
        "\n",
        "\n",
        "     self.data=pd.read_csv(csv_file)\n",
        "\n",
        "     self.x=self.data[\"path\"]\n",
        "     self.y=self.data[\"etiqueta\"]\n",
        "\n",
        "     self.transform=transform\n",
        "\n",
        "     self.samples=self.data[\"path\"].shape[0]\n",
        "\n",
        "\n",
        "  def __getitem__(self,id):\n",
        "\n",
        "    rut_imagen=self.x[id]\n",
        "    imagen=cv2.imread(rut_imagen)\n",
        "\n",
        "    imagen_rgb = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n",
        "    etiqueta=self.y[id]\n",
        "\n",
        "    if self.transform:\n",
        "      imagen_rgb = self.transform(imagen_rgb)\n",
        "\n",
        "    return imagen_rgb,etiqueta\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "   return self.samples\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S7i_BABFA3pQ"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@markdown # *3) ** Separacion dos archivos difentes para entrenamietno y prueba(OBLIGATORIO)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "misdatos=pd.read_csv(\"/content/Data_set_paths.csv\")\n",
        "# Separo mis datos en entrenamiento y test\n",
        "datos_entrenamiento, datos_evaluacion = train_test_split(misdatos, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "# Guardar los dos conjuntos en archivos CSV separados\n",
        "datos_entrenamiento.to_csv(\"/content/datos_entrenamiento.csv\", index=False)\n",
        "datos_evaluacion.to_csv(\"/content/datos_evaluacion.csv\", index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G-a_w8fbwHPx"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *2) ** Mostrar 20 muestras(Opcional)\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Definir transformaciones\n",
        "transformaciones = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((100, 100))\n",
        "])\n",
        "\n",
        "# Crear dataset y DataLoader\n",
        "muestra = MiDataSet(\"/content/datos_entrenamiento.csv\", transformaciones)\n",
        "data_muestra = DataLoader(muestra, batch_size=20, shuffle=True)\n",
        "\n",
        "# Obtener el primer lote\n",
        "primer_lote = next(iter(data_muestra))\n",
        "tensor_imagenes, tensor_etiquetas = primer_lote\n",
        "\n",
        "# Mapeo de etiquetas numéricas a etiquetas de texto\n",
        "mapeo_etiquetas = {0: 'gato', 1: 'perro'}\n",
        "etiquetas_texto = [mapeo_etiquetas[item.item()] for item in tensor_etiquetas]\n",
        "\n",
        "# Crear una figura y subgráficos\n",
        "fig, axs = plt.subplots(4, 5, figsize=(20, 20))\n",
        "\n",
        "# Iterar sobre las imágenes del lote\n",
        "for i in range(4):\n",
        "    for j in range(5):\n",
        "        idx = i * 5 + j\n",
        "        imagen = tensor_imagenes[idx].permute(1, 2, 0)\n",
        "        etiqueta_texto = etiquetas_texto[idx]\n",
        "\n",
        "        # Mostrar la imagen en el subgráfico correspondiente\n",
        "        axs[i, j].imshow(imagen)\n",
        "        axs[i, j].set_title(etiqueta_texto)\n",
        "        axs[i, j].axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Q28aUbrG2IW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "transformaciones = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((100, 100))\n",
        "])\n",
        "\n",
        "mis_datos_entrenamiento=MiDataSet(\"/content/datos_entrenamiento.csv\",transform=transformaciones)\n",
        "\n",
        "mis_datos_test=MiDataSet(\"/content/datos_evaluacion.csv\",transform=transformaciones)\n",
        "\n",
        "\n",
        "data_por_lote_entrenamiento=DataLoader(mis_datos_entrenamiento,batch_size=100,shuffle=True)\n",
        "\n",
        "data_por_por_lote_test=DataLoader(mis_datos_test,batch_size=100,shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "datos_features_train,datos_label_train=next(iter(data_por_lote_entrenamiento))\n",
        "\n",
        "datos_features_test,datos_label_test=next(iter(data_por_por_lote_test))\n",
        "\n",
        "\n",
        "print(datos_features_train.shape)\n",
        "print(datos_features_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "zOqxrfSRJivq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f796b0ef-4d58-4ae2-85da-7ba90ae37e40"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 3, 100, 100])\n",
            "torch.Size([100, 3, 100, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "class RedConvolucional(nn.Module):\n",
        "\n",
        "   def __init__(self):\n",
        "    super(RedConvolucional,self).__init__()\n",
        "\n",
        "#Red convolulcional\n",
        "\n",
        "    self.conv1=nn.Conv2d(in_channels=3,out_channels=6,kernel_size=3, stride=1, padding=1)\n",
        "    self.conv2=nn.Conv2d(in_channels=6,out_channels=12,kernel_size=3, stride=1, padding=1)\n",
        "    self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.conv3=nn.Conv2d(in_channels=12,out_channels=24,kernel_size=3, stride=1, padding=1)\n",
        "    self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.conv4=nn.Conv2d(in_channels=24,out_channels=48,kernel_size=3, stride=2, padding=1)\n",
        "    self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.flatten=nn.Flatten()\n",
        "\n",
        "#Red fully conected o multicapa convecional\n",
        "\n",
        "    self.capa_oculta=nn.Linear(1728,100)\n",
        "\n",
        "    self.capa_salida=nn.Linear(100,2)\n",
        "\n",
        "\n",
        "   def forward(self,x):\n",
        "    #Capa convolucionales\n",
        "     x=self.conv1(x)\n",
        "     x=F.relu(x)\n",
        "\n",
        "     x=self.conv2(x)\n",
        "     x=F.relu(x)\n",
        "     x=self.maxpool1(x)\n",
        "\n",
        "     x=self.conv3(x)\n",
        "     x=F.relu(x)\n",
        "     x=self.maxpool2(x)\n",
        "\n",
        "     x=self.conv4(x)\n",
        "     x=F.relu(x)\n",
        "     x=self.maxpool3(x)\n",
        "     x=self.flatten(x)\n",
        "\n",
        "#Capa fully conected\n",
        "     x=self.capa_oculta(x)\n",
        "     x=F.relu(x)\n",
        "\n",
        "     x=self.capa_salida(x)\n",
        "     output=F.softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     return output\n"
      ],
      "metadata": {
        "id": "pPePfzy31mvx"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#funcion clasificador:\n",
        "def clasificador(y_pred_test):\n",
        " max_values_tensor=torch.empty((0,),dtype=torch.float32)\n",
        "\n",
        " for tensor in y_pred_test:\n",
        "   max_values,max_indices=torch.max(tensor,dim=0)\n",
        "\n",
        "   max_values_tensor=torch.cat((max_values_tensor,max_indices.unsqueeze(0)))\n",
        "\n",
        " return max_values_tensor\n",
        "\n",
        "#funcion acutity:\n",
        "def accurity(y_test,y_real):\n",
        "   correctos=0\n",
        "   for predicho, real in zip(y_test, y_real):\n",
        "    if predicho==real:\n",
        "     correctos+=1\n",
        "   return correctos/len(y_test)\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "ModeloRC=RedConvolucional()\n",
        "\n",
        "criterio=nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer=optim.SGD(ModeloRC.parameters(),lr=0.1)\n",
        "\n",
        "epochs=6\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        " for i,(xi,yi) in enumerate(data_por_lote_entrenamiento):\n",
        "\n",
        "    y_predict=ModeloRC(xi)\n",
        "    y_predic_train_clasificado=clasificador(y_predict)\n",
        "\n",
        "    loss=criterio(y_predic_train_clasificado,yi.float())\n",
        "\n",
        "\n",
        " loss.backward()\n",
        " optimizer.step()\n",
        " optimizer.zero_grad()\n",
        "\n",
        " with torch.no_grad():\n",
        "   for i,(xi,yi) in enumerate(data_por_por_lote_test):\n",
        "    y_predict_test=ModeloRC(xi)\n",
        "    y_predic_test_clasificado=clasificador(yi)\n",
        "\n",
        "   Precision=accurity(y_predict_test,y_predic_test_clasificado)\n",
        "   print(f'Epoca[{epoch+1}],Perdida: {loss.item():.4f} ,Accuracy: {Precision:.4f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eb2AfYxQchgT",
        "outputId": "09458ab0-6768-4211-daa6-b9fd01152556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2465750c8b53>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mModeloRC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRedConvolucional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mcriterio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RedConvolucional' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "y_pred_multiclases = torch.tensor([[0.1, 1.8, 0.8, 0.4, 2],\n",
        "                                   [0.5, 2, 3.5, 5, 2.1]])\n",
        "\n",
        "def clasificador(y_pred_test):\n",
        "\n",
        "   max_values_tensor = torch.empty((0,), dtype=torch.float32)\n",
        "\n",
        "   for tensor in y_pred_test:\n",
        "\n",
        "     max_values, max_indices  = torch.max(tensor, dim=0)\n",
        "\n",
        "     max_values_tensor = torch.cat((max_values_tensor, max_indices.unsqueeze(0)))\n",
        "\n",
        "   return max_values_tensor\n",
        "\n",
        "print(clasificador(y_pred_multiclases))\n"
      ],
      "metadata": {
        "id": "7LqpXE2_9vpy",
        "outputId": "c10e4aa3-a539-4e8d-df5a-8dfd2f076f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4., 3.])\n"
          ]
        }
      ]
    }
  ]
}