{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuniorHZ19/ML/blob/main/perceptronmulticapa5.5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nEH5XojTlDKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ebaa25-106e-4544-8dbd-6972a5c4b3e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class MiDataSet(Dataset):\n",
        "\n",
        "  def __init__(self,csv_file):\n",
        "\n",
        "     data=pd.read_csv(csv_file)\n",
        "\n",
        "     self.x,self.y= self.limpiezaDatos(data)\n",
        "\n",
        "     self.samples=self.y.shape[0]\n",
        "\n",
        "\n",
        "  def __getitem__(self,id):\n",
        "\n",
        "   return self.x[id],self.y[id]\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "   return self.samples\n",
        "\n",
        "\n",
        "  def limpiezaDatos(self,data):\n",
        "\n",
        "    data=data.dropna(how=\"all\")\n",
        "\n",
        "    data=data.drop_duplicates()\n",
        "\n",
        "    data=data.drop(columns=[\"name\",\"ticket\",\"cabin\",\"boat\",\"body\",\"home.dest\"])\n",
        "\n",
        "    data[[\"age\",\"fare\"]]=data[[\"age\",\"fare\"]].fillna(data[[\"age\",\"fare\"]].mean())\n",
        "\n",
        "    data[\"embarked\"]=data[\"embarked\"].fillna(\"S\")\n",
        "\n",
        "    data[\"age\"]=data[\"age\"].astype(int)\n",
        "\n",
        "    data=pd.get_dummies (data,columns=[\"sex\",\"embarked\"],prefix=[\"sex\",\"embarked\"])\n",
        "\n",
        "    variables_x=data.drop(columns=[\"survived\"])\n",
        "\n",
        "    variable_y=data[\"survived\"]\n",
        "\n",
        "    return variables_x.values,  variable_y.values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S7i_BABFA3pQ"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gmEfz4kydlJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "mis_datos=MiDataSet(\"/content/titanic.csv\")\n",
        "\n",
        "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(mis_datos.x, mis_datos.y, test_size=0.2, random_state=0,stratify=mis_datos.y)\n",
        "\n",
        "print(X_entrenamiento.shape)\n",
        "\n",
        "print(X_prueba)\n",
        "\n",
        "print(y_entrenamiento.shape)\n",
        "\n",
        "print(y_prueba)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zOqxrfSRJivq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5bd7fe6-7bf8-452f-ad14-047c7b7ca269"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1047, 10)\n",
            "[[ 2. 34.  1. ...  0.  0.  1.]\n",
            " [ 2. 24.  0. ...  0.  0.  1.]\n",
            " [ 3. 26.  0. ...  0.  1.  0.]\n",
            " ...\n",
            " [ 2. 34.  0. ...  0.  0.  1.]\n",
            " [ 3.  2.  4. ...  0.  0.  1.]\n",
            " [ 2.  0.  1. ...  0.  0.  1.]]\n",
            "(1047,)\n",
            "[0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 1\n",
            " 1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0\n",
            " 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1\n",
            " 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1\n",
            " 0 1 0 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0\n",
            " 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0\n",
            " 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0\n",
            " 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_entrenamiento=torch.from_numpy(y_entrenamiento)\n",
        "print(y_entrenamiento.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4sMn-5NH45S",
        "outputId": "0274dea2-59c6-4012-91f8-f8a2aa0ddbf9"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1047])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "escaladorDatosx=StandardScaler()\n",
        "\n",
        "x_train_esclados=torch.from_numpy(escaladorDatosx.fit_transform(X_entrenamiento)).float()\n",
        "y_entrenamiento=torch.from_numpy(y_entrenamiento).float()\n",
        "x_test_escalados=torch.from_numpy(escaladorDatosx.transform(X_prueba)).float()\n",
        "y_prueba=torch.from_numpy(y_prueba).float()\n",
        "\n",
        "\n",
        "conjunto_entrenamiento = TensorDataset(x_train_esclados,y_entrenamiento )\n",
        "\n",
        "conjunto_prueba = TensorDataset(x_test_escalados, y_prueba)\n",
        "\n",
        "data_por_lote_entrenamiento=DataLoader(conjunto_entrenamiento,batch_size=10,shuffle=True)\n",
        "\n",
        "data_por_por_lote_test=DataLoader(conjunto_prueba,batch_size=10,shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "#datos_features_train,datos_label_train=next(iter(data_por_lote_entrenamiento))\n",
        "\n",
        "#datos_features_test,datos_label_test=next(iter(data_por_por_lote_test))\n",
        "\n",
        "\n",
        "print(data_por_lote_entrenamiento.batch_size)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2jQ67LCbKprh",
        "outputId": "1da5e0a3-3c27-4abf-deac-5a882210c546",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "modelo=torch.Sequential(\n",
        "\n",
        "                        torch.nn.Linear(input_size,3),\n",
        "                        torch.nn.ReLU(),\n",
        "\n",
        "                        torch.nn.Linear(3,4),\n",
        "                        torch.nn.ReLU(),\n",
        "\n",
        "                        torch.nn.Linear(4,1),\n",
        "                        torch.nn.Sigmoid()\n",
        ")"
      ],
      "metadata": {
        "id": "7WMFZMRih-Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "class PerceptronMulticapa(nn.Module):\n",
        "\n",
        "   def __init__(self,input_size):\n",
        "    super(PerceptronMulticapa,self).__init__()\n",
        "    print(input_size)\n",
        "\n",
        "    self.fc1=nn.Linear(input_size,3)\n",
        "\n",
        "    self.fc2=nn.Linear(3,4)\n",
        "\n",
        "    self.capa_salida =nn.Linear(4,1)\n",
        "\n",
        "   def forward(self,x):\n",
        "\n",
        "     x=self.fc1(x)\n",
        "     x=F.relu(x)\n",
        "\n",
        "     x=self.fc2(x)\n",
        "     x=F.relu(x)\n",
        "\n",
        "     output=self.capa_salida(x)\n",
        "\n",
        "\n",
        "\n",
        "     return output\n"
      ],
      "metadata": {
        "id": "pPePfzy31mvx"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA está disponible.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"CUDA no está disponible. Se utilizará la CPU.\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "xwtxORPcuDNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a938a1-24dd-423f-8ad7-a56e3092ee21"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA no está disponible. Se utilizará la CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "#funcion clasificador:\n",
        "def clasificador(y_pred_test):\n",
        "\n",
        "  umbral = 0.6\n",
        "  y_pred_test_binario = (y_pred_test >= umbral).to(torch.float32)\n",
        "  return y_pred_test_binario\n",
        "\n",
        "#funcion acutity:\n",
        "\n",
        "def accuracy(y_test, y_real):\n",
        "    correctos = torch.sum(y_test == y_real).item()\n",
        "\n",
        "    return (correctos / len(y_test))\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "\n",
        "def TrainMLP(modelo,epochs,optimisador,criterio,input_size,data_Loader_entrenamiento,data_Loader_test):\n",
        "\n",
        " for epoch in range(epochs):\n",
        "\n",
        "  total_train_loss = 0.0\n",
        "  num_train_batches = len(data_Loader_entrenamiento)\n",
        "  modelo.train()\n",
        "\n",
        "  for x_entrenamiento,y_entrenamiento in (data_Loader_entrenamiento):\n",
        "   x_entrenamiento,y_entrenamiento=x_entrenamiento.to(device),y_entrenamiento.to(device)\n",
        "\n",
        "   y_predict=modelo(x_entrenamiento)\n",
        "\n",
        "   loss=criterio(y_predict,y_entrenamiento.view(-1,1))\n",
        "\n",
        "   loss.backward()\n",
        "   optimisador.step()\n",
        "   optimisador.zero_grad()\n",
        "   total_train_loss+=loss.item()\n",
        "\n",
        "  modelo.eval()\n",
        "  with torch.no_grad():\n",
        "    total_test_accuracy = 0.0\n",
        "    num_test_batches = len(data_Loader_test)\n",
        "\n",
        "    for X_prueba,y_prueba in (data_Loader_test):\n",
        "\n",
        "     X_prueba,y_prueba=X_prueba.to(device),y_prueba.to(device)\n",
        "     y_predict_test=modelo(X_prueba)\n",
        "     y_predict_test_p=torch.sigmoid(y_predict_test)\n",
        "     y_predic_test_clasificado=clasificador(y_predict_test_p)\n",
        "     Precision=accuracy(y_predic_test_clasificado,y_prueba.view(-1,1))\n",
        "     total_test_accuracy += Precision\n",
        "\n",
        "  avg_test_accuracy = (total_test_accuracy / num_test_batches)\n",
        "  avg_train_loss=(total_train_loss/num_train_batches)\n",
        "  print(f'Epoca[{epoch+1}], Perdida: {avg_train_loss:.4f},Accuryty:{avg_test_accuracy:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "\n",
        "input_sizes=10\n",
        "\n",
        "PerceptronMulti=PerceptronMulticapa(input_sizes)\n",
        "\n",
        "criterios=nn.BCEWithLogitsLoss() # automaticamente aplica el sigmoide a la capa de salida y clasfica 0 -1 para el loss\n",
        "\n",
        "optimizer=optim.SGD(PerceptronMulti.parameters(),lr=0.01)\n",
        "\n",
        "epocas=500\n",
        "\n",
        "PerceptronMulti=PerceptronMulti.to(device)\n",
        "\n",
        "TrainMLP(PerceptronMulti,epocas,optimizer,criterios,input_sizes,data_por_lote_entrenamiento,data_por_por_lote_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eb2AfYxQchgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nuevo datos:\n",
        "\n",
        "def escalarNuevaData(data):\n",
        "\n",
        "    scaler=StandardScaler()\n",
        "\n",
        "    datos_escalados=scaler.fit_transform(data)\n",
        "\n",
        "    datos_x_tensor=torch.from_numpy(datos_escalados).float()\n",
        "    print(datos_escalados)\n",
        "    return datos_x_tensor\n",
        "\n",
        "nuevo_x=escaladorDatosx.transform([[1,20,1,0,151,0,1,0,0,1]])\n",
        "nuevo_X_transform=torch.from_numpy(escaladorDatosx.transform(nuevo_x)).float()\n",
        "\n",
        "y_predict=PerceptronMulti(nuevo_X_transform)\n",
        "\n",
        "print(clasificador(y_predict))\n",
        "\n"
      ],
      "metadata": {
        "id": "X8ZpEP6be9hg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587e65e6-3a2b-4079-9f2b-2488f234a6f6"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "y_pred_multiclases = torch.tensor([[0.1, 1.8, 0.8, 0.4, 2],\n",
        "                                   [0.5, 2, 3.5, 5, 2.1]])\n",
        "\n",
        "def clasificador(y_pred_test):\n",
        "\n",
        "   max_values_tensor = torch.empty((0,), dtype=torch.float32)\n",
        "\n",
        "   for tensor in y_pred_test:\n",
        "\n",
        "     max_values, max_indices  = torch.max(tensor, dim=0)\n",
        "\n",
        "     max_values_tensor = torch.cat((max_values_tensor, max_indices.unsqueeze(0)))\n",
        "\n",
        "   return max_values_tensor\n",
        "\n",
        "print(clasificador(y_pred_multiclases))\n"
      ],
      "metadata": {
        "id": "7LqpXE2_9vpy",
        "outputId": "c10e4aa3-a539-4e8d-df5a-8dfd2f076f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4., 3.])\n"
          ]
        }
      ]
    }
  ]
}